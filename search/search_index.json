{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Wes Roach - Summary","text":""},{"location":"index.html#work","title":"Work","text":"<p>I currrently lead a team of developers @First American building a solution for expedited title commitment &amp; insurance delivery.</p> <p>I previous led a team of developers @GDIT providing insight and IT services to the Arkansas Department of Human Services' Medicaid system. I was a key contributor to the Arkansas Payment Improvement Initiative since its inception in 2013 and served as one of the lead analysts for the program until 2021.</p>"},{"location":"about.html","title":"About Me","text":""},{"location":"about.html#life","title":"Life","text":"<p>I live in Austin, Texas with my wife, son, and our cat.</p> <p></p>"},{"location":"about.html#academic","title":"Academic","text":"School Degree Specialty Graduation Syracuse University Master of Science in Computer Science May 2024 Unversity of Arkansas for Medical Sciences Master of Public Health Biostatistics 2013 University of Central Arkanas Bachelor of Science Biology (Chemistry minor) 2009"},{"location":"license.html","title":"License","text":""},{"location":"license.html#mkdocs-license-bsd","title":"MkDocs License (BSD)","text":"<p>Copyright \u00a9 2014, Tom Christie. All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <p>Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.</p> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"license.html#theme-material-for-mkdocs","title":"Theme: Material for MkDocs","text":"<p>MIT License</p> <p>Copyright \u00a9 2016 - 2017 Martin Donath</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"dask/dask.html","title":"Dask Working Notes","text":""},{"location":"dask/dask.html#rotate-long-column-wide-multiple","title":"Rotate Long Column Wide - Multiple","text":"<pre><code>import pandas as pd\nimport dask.dataframe as dd\nimport numpy as np\n\n\ndef convert_dates_to_strings(df, date_columns: list, date_format) -&gt; dd.DataFrame:\n    for col in date_columns:\n        df[col] = df[col].dt.strftime(date_format)\n        df[col] = df[col].replace(\"01011800\", \"\")\n    return df\n\n\ndf = pd.DataFrame(\n    {\n        \"bene_id\": [\"1\", \"1\", \"1\", \"1\", \"1\"],\n        \"hdr_icn\": [\"1\", \"1\", \"2\", \"2\", \"2\"],\n        \"rot1\": [\"A\", \"B\", \"C\", \" \", \"E\"],\n        \"rot2\": [\"X\", \"Y\", \"Z\", \" \", \" \"],\n        \"rot3\": [\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n        ],\n    }\n)\nddf = dd.from_pandas(df, 4)\nddf = convert_dates_to_strings(ddf, [\"rot3\"], \"%m%d%Y\")\nddf = ddf.set_index(\"bene_id\").persist()\n\n\ndef agg_func(x):\n    return pd.Series(\n        dict(\n            # 14.7 ms \u00b1 287 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n            # rot1=\"%s\" % \";\".join(x[\"rot1\"]),\n            # rot2=\"%s\" % \";\".join(x[\"rot2\"]),\n            # rot3=\"%s\" % \";\".join(x[\"rot3\"]),\n            # 14.7 ms \u00b1 493 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n            # rot1=f'{\";\".join(x[\"rot1\"])}',\n            # rot2=f'{\";\".join(x[\"rot2\"])}',\n            # rot3=f'{\";\".join(x[\"rot3\"])}',\n            # 14.8 ms \u00b1 314 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n            rot1=\";\".join(x[\"rot1\"]),\n            rot2=\";\".join(x[\"rot2\"]),\n            rot3=\";\".join(x[\"rot3\"]),\n        )\n    )\n\n\nddf.groupby([\"bene_id\", \"hdr_icn\"]).apply(\n    agg_func, meta={\"rot1\": \"str\", \"rot2\": \"str\", \"rot3\": \"str\"}\n).compute()\n</code></pre> <p>We can condense some of this code down by passing a list of columns to agg_func.</p> <pre><code>import pandas as pd\nimport dask.dataframe as dd\nimport numpy as np\n\n\ndef convert_dates_to_strings(df, date_columns: list, date_format) -&gt; dd.DataFrame:\n    for col in date_columns:\n        df[col] = df[col].dt.strftime(date_format)\n        df[col] = df[col].replace(\"01011800\", \"\")\n    return df\n\n\ndf = pd.DataFrame(\n    {\n        \"bene_id\": [\"1\", \"1\", \"1\", \"1\", \"1\"],\n        \"hdr_icn\": [\"1\", \"1\", \"2\", \"2\", \"2\"],\n        \"rot1\": [\"A\", \"B\", \"C\", \" \", \"E\"],\n        \"rot2\": [\"X\", \"Y\", \"Z\", \" \", \" \"],\n        \"rot3\": [\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n        ],\n    }\n)\nddf = dd.from_pandas(df, 4)\nddf = convert_dates_to_strings(ddf, [\"rot3\"], \"%m%d%Y\")\nddf = ddf.set_index(\"bene_id\").persist()\n\n\ndef agg_func(x, cols):\n    return pd.Series({col: \";\".join(x[col]) for col in cols})\n\n\nddf.groupby([\"bene_id\", \"hdr_icn\"]).apply(agg_func, [\"rot1\", \"rot2\", \"rot3\"]).compute()\n</code></pre> <p>We can further reduce runtime by providing agg_func with the expected \"meta\" output from .apply(...)</p> <pre><code>import pandas as pd\nimport dask.dataframe as dd\nimport numpy as np\n\n\ndef convert_dates_to_strings(df, date_columns: list, date_format) -&gt; dd.DataFrame:\n    for col in date_columns:\n        df[col] = df[col].dt.strftime(date_format)\n        df[col] = df[col].replace(\"01011800\", \"\")\n    return df\n\n\ndf = pd.DataFrame(\n    {\n        \"bene_id\": [\"1\", \"1\", \"1\", \"1\", \"1\"],\n        \"hdr_icn\": [\"1\", \"1\", \"2\", \"2\", \"2\"],\n        \"rot1\": [\"A\", \"B\", \"C\", \" \", \"E\"],\n        \"rot2\": [\"X\", \"Y\", \"Z\", \" \", \" \"],\n        \"rot3\": [\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n        ],\n    }\n)\nddf = dd.from_pandas(df, 4)\nddf = convert_dates_to_strings(ddf, [\"rot3\"], \"%m%d%Y\")\nddf = ddf.set_index(\"bene_id\").persist()\n\n\ndef agg_func(x, cols):\n    return pd.Series({col: \";\".join(x[col]) for col in cols})\n\n\n# On a subset of data, pass the groupby object to dask.dataframe.utils.make_meta()\nddf_meta = dd.utils.make_meta(ddf.groupby([\"bene_id\", \"hdr_icn\"]).apply(agg_func, [\"rot1\", \"rot2\", \"rot3\"]))\n# You can view what you'll need to use as the meta object by accessing ddf_meta &amp; ddf_meta.index\n&gt;&gt; ddf_meta\nEmpty DataFrame\nColumns: [rot1, rot2, rot3]\nIndex: []\n\n&gt;&gt; ddf_meta.index\nMultiIndex(levels=[['a', 'b'], ['foo']],\n           codes=[[], []],\n           names=['bene_id', 'hdr_icn'])\n\n# The ddf_meta object obviously wont be available @ runtime - we use the output to manually define\n# the object's properties\n\ntyped_ddf_meta = pd.DataFrame(\n    columns=[\"rot1\", \"rot2\", \"rot3\"],\n    index=pd.MultiIndex(\n        levels=[[\"a\", \"b\"], [\"foo\"]], codes=[[], []], names=[\"bene_id\", \"hdr_icn\"]\n    ),\n)\ntyped_ddf_meta = ddf_meta.astype(dtype={\"rot1\": \"str\", \"rot2\": \"str\", \"rot3\": \"str\"})\n\n# note that the output of typed_ddf_meta and ddf_meta are equivalent\n\n# you can now pass typed_ddf_meta as the meta object to .apply() - you should notice a marginal speedup\nddf.groupby([\"bene_id\", \"hdr_icn\"]).apply(agg_func, [\"rot1\", \"rot2\", \"rot3\"], meta=typed_ddf_meta).compute()\n</code></pre> <p>It wouldn't make sense to run the .groupby() @ runtime, every time, to generate the meta_ddf information, so we'll define it by hand below:</p> <pre><code>import pandas as pd\nimport dask.dataframe as dd\nimport numpy as np\n\n\ndef convert_dates_to_strings(df, date_columns: list, date_format) -&gt; dd.DataFrame:\n    for col in date_columns:\n        df[col] = df[col].dt.strftime(date_format)\n        df[col] = df[col].replace(\"01011800\", \"\")\n    return df\n\n\ndf = pd.DataFrame(\n    {\n        \"bene_id\": [\"1\", \"1\", \"1\", \"1\", \"1\"],\n        \"hdr_icn\": [\"1\", \"1\", \"2\", \"2\", \"2\"],\n        \"rot1\": [\"A\", \"B\", \"C\", \" \", \"E\"],\n        \"rot2\": [\"X\", \"Y\", \"Z\", \" \", \" \"],\n        \"rot3\": [\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n            pd.to_datetime(\"2018-01-01\"),\n        ],\n    }\n)\nddf = dd.from_pandas(df, 4)\nddf = convert_dates_to_strings(ddf, [\"rot3\"], \"%m%d%Y\")\nddf = ddf.set_index(\"bene_id\").persist()\n\n\ndef agg_func(x, cols):\n    return pd.Series({col: \";\".join(x[col]) for col in cols})\n\n\n# Create ddf_meta object representing expected output from .apply()\nddf_meta = pd.DataFrame(\n    columns=[\"rot1\", \"rot2\", \"rot3\"],\n    index=pd.MultiIndex(\n        levels=[[\"a\", \"b\"], [\"foo\"]], codes=[[], []], names=[\"bene_id\", \"hdr_icn\"]\n    ),\n)\nddf_meta = ddf_meta.astype(dtype={\"rot1\": \"str\", \"rot2\": \"str\", \"rot3\": \"str\"})\n\n# Pass ddf_meta to .apply(..., meta=ddf_meta)\nddf.groupby([\"bene_id\", \"hdr_icn\"]).apply(agg_func, [\"rot1\", \"rot2\", \"rot3\"], meta=ddf_meta).compute()\n</code></pre>"},{"location":"dask/dask.html#joining-on-index-separate-column","title":"Joining on Index + Separate Column","text":""},{"location":"dask/dask.html#setup-data","title":"Setup Data","text":"<pre><code>import pandas as pd\nimport dask.dataframe as dd\n\nfrom io import StringIO\n\nddf1_string = StringIO(\n    \"\"\"hdr_icn_num,ver,col1\n1,1,foo\n2,1,foo\n3,1,foo\n4,1,foo\n5,1,foo\n    \"\"\"\n)\nddf1 = dd.from_pandas(pd.read_csv(ddf1_string, sep=\",\"), 5)\nddf1 = ddf1.set_index(\"hdr_icn_num\")\n\nddf2_string = StringIO(\n    \"\"\"hdr_icn_num,ver,col2,col3\n1,1,bar!,baz\n1,2,X,X\n2,1,bar!,\n2,2,X,X\n3,1,bar!,baz\n3,2,X,X\n4,1,bar!,\n4,2,X,X\n5,1,bar!,baz\n5,2,X,X\n    \"\"\"\n)\n\nddf2 = dd.from_pandas(pd.read_csv(ddf2_string, sep=\",\", keep_default_na=False), 5)\nddf2 = ddf2.set_index(\"hdr_icn_num\")\n\nddf1.head(10, ddf1.npartitions)\n\nddf2.head(10, ddf2.npartitions)\n</code></pre>"},{"location":"dask/dask.html#works","title":"Works","text":"<pre><code>join_df = dd.merge(\n    left=ddf1,\n    right=ddf2,\n    on=[\"hdr_icn_num\"],\n    left_on=[\"hdr_icn_num\", \"ver\"],\n    right_on=[\"hdr_icn_num\", \"ver\"],\n    how=\"left\",\n)\njoin_df.head(10, join_df.npartitions)\n</code></pre>"},{"location":"dask/dask.html#works_1","title":"Works","text":"<pre><code>join_df = dd.merge(\n    left=ddf1,\n    right=ddf2,\n    left_on=[\"hdr_icn_num\", \"ver\"],\n    right_on=[\"hdr_icn_num\", \"ver\"],\n    how=\"left\",\n)\njoin_df.head(10, join_df.npartitions)\n</code></pre>"},{"location":"dask/dask.html#does-not-work","title":"Does Not Work","text":"<pre><code>join_df = dd.merge(\n    left=ddf1,\n    right=ddf2,\n    left_index=True,\n    right_index=True,\n    left_on=[\"ver\"],\n    right_on=[\"ver\"],\n    how=\"left\",\n)\njoin_df.head(10, join_df.npartitions)\n</code></pre>"},{"location":"dask/dask.html#task-scheduler-notes","title":"Task / Scheduler Notes","text":""},{"location":"dask/dask.html#run-on-scheduler","title":"Run on Scheduler","text":"<p><code>client.run_on_scheduler</code> takes a custom function. The custom function should include an argument <code>dask_scheduler</code> if the custom function requires access to the Scheduler object and its API.</p> <pre><code>client = Client(\"etcetc\")\n\n# shows tasks on workers\nclient.has_what()\n\ndef get_task_stream(dask_scheduler):\n    # Shows tasks that have been run/submitted in the past?\n    return dask_scheduler.get_task_stream() \n\ndef kill_task_across_clients(dask_sheduler, task_key):\n    # Kill some task that exist w/some client\n    # task_key == 'etc_etc-c07efb0ea6dd8c15df9a948ccd19e28c'\n    for client in dask_scheduler.clients:\n        dask_scheduler.cancel_key(key=task_key, client=client)\n\ntask_stream = client.run_on_scheduler(get_task_stream)\n\ndef user_info() -&gt; dict:\n    \"\"\"\n    Returns dict of user information for the current process.\n\n    Returns: Dict\n    \"\"\"\n    import os\n    import getpass\n\n    return dict(\n        uid=os.geteuid(),\n        gid=os.getgid(),\n        egid=os.getegid(),\n        groups=os.getgroups(),\n        user=getpass.getuser(),\n    )\n\n# Retrieve user info for the scheduler owner\nclient.run_on_scheduler(user_info)\nuser_info()\n</code></pre>"},{"location":"data-engineering/etl.html","title":"ETL","text":""},{"location":"data-engineering/etl.html#primary-concerns","title":"Primary Concerns","text":"<ul> <li>Logical</li> <li>Schema Changes</li> <li>Type Conversions</li> <li>Idempotence</li> <li>Orchestration</li> <li>Error Handling</li> <li>Observability</li> <li>Scheduling</li> </ul>"},{"location":"kubernetes/edx.html","title":"EDx","text":""},{"location":"kubernetes/edx.html#ch1-container-orchestration","title":"Ch1. Container Orchestration","text":""},{"location":"kubernetes/edx.html#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Define the concept of container orchestration.</li> <li>Explain the reasons for doing container orchestration.<ul> <li>Can not provision underlying architecture.</li> </ul> </li> <li>Discuss different container orchestration options.</li> <li>Discuss different container orchestration deployment options.</li> </ul>"},{"location":"kubernetes/edx.html#ch2-kubernetes","title":"Ch2. Kubernetes","text":""},{"location":"kubernetes/edx.html#define-kubernetes","title":"Define Kubernetes.","text":"<p>\"Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\"</p> <ul> <li>k8s</li> <li>based on Google's Borg<ul> <li>API Servers</li> <li>Pods</li> <li>IP-per-Pod</li> <li>Services</li> <li>Labels</li> </ul> </li> <li>Written in Go</li> <li>Apache License Version 2.0</li> <li>Google =&gt; CNCF July 2015</li> </ul>"},{"location":"kubernetes/edx.html#explain-the-reasons-for-using-kubernetes","title":"Explain the reasons for using Kubernetes.","text":""},{"location":"kubernetes/edx.html#discuss-the-features-of-kubernetes","title":"Discuss the features of Kubernetes.","text":"<ul> <li>Automatic binpacking<ul> <li>Kubernetes automatically schedules the containers based on resource usage - and constraints, without sacrificing the availability.</li> </ul> </li> <li>Self-healing<ul> <li>Kubernetes automatically replaces and reschedules the containers from failed nodes. It also kills and restarts the containers which do not respond to health checks, based on existing rules/policy.</li> </ul> </li> <li>Horizontal scaling<ul> <li>Kubernetes can automatically scale applications based on resource usage like CPU and memory. In some cases, it also supports dynamic scaling based on customer metrics.</li> </ul> </li> <li>Service discovery and Load balancing<ul> <li>Kubernetes groups sets of containers and refers to them via a Domain Name System (DNS). This DNS is also called a Kubernetes service. Kubernetes can discover these services automatically, and load-balance requests between - containers of a given service.</li> </ul> </li> <li>Automated rollouts and rollbacks<ul> <li>Kubernetes can roll out and roll back new versions/configurations of an application, without introducing any downtime.</li> </ul> </li> <li>Secrets and configuration management<ul> <li>Kubernetes can manage secrets and configuration details for an application without re-building the respective images. With secrets, we can share confidential information to our application without exposing it to the stack configuration, like on GitHub.</li> </ul> </li> <li>Storage orchestration<ul> <li>With Kubernetes and its plugins, we can automatically mount local, external, and storage solutions to the containers in a seamless manner, based on software-defined storage (SDS).</li> </ul> </li> <li>Batch execution<ul> <li>Besides long running jobs, Kubernetes also supports batch execution.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#discuss-the-evolution-of-kubernetes-from-borg","title":"Discuss the evolution of Kubernetes from Borg.","text":""},{"location":"kubernetes/edx.html#explain-what-the-cloud-native-computing-foundation-does","title":"Explain what the Cloud Native Computing Foundation does.","text":"<ul> <li>One of the projects hosted by The Linux Foundation</li> <li>CNCF hosts a set of projects, with more to be added in the future. CNCF provides resources to each of the projects, but, at the same time, each project continues to operate independently under its pre-existing governance structure and with its existing maintainers.<ul> <li>containerd for container runtime</li> <li>rkt for container runtime</li> <li>Kubernetes for container orchestration</li> <li>Linkerd for service mesh</li> <li>Envoy for service mesh</li> <li>gRPC for remote procedure call (RPC)</li> <li>Container Network Interface (CNI) for networking API</li> <li>CoreDNS for service discovery</li> <li>Rook for cloud-native storage</li> <li>Notary for security</li> <li>The Update Framework (TUF) for software updates</li> <li>Prometheus for monitoring</li> <li>OpenTracing for tracing</li> <li>Jaeger for distributed tracing</li> <li>Fluentd for logging</li> <li>Vitess for storage.</li> </ul> </li> </ul> <p>For Kubernetes, the Cloud Native Computing Foundation:</p> <ul> <li>Provides a neutral home for the Kubernetes trademark and enforces proper usage</li> <li>Provides license scanning of core and vendored code</li> <li>Offers legal guidance on patent and copyright issues</li> <li>Creates open source curriculum, training, and certification</li> <li>Manages a software conformance working group</li> <li>Actively markets Kubernetes</li> <li>Hosts and funds developer marketing activities like K8Sport</li> <li>Supports ad hoc activities</li> <li>Funds conferences and meetup events.</li> </ul>"},{"location":"kubernetes/edx.html#ch3-kubernets-architecture","title":"Ch3. Kubernets Architecture","text":"<p>Terms:</p> <ul> <li>master</li> <li>worker nodes</li> <li>etcd</li> <li>Container Network Interface (CNI)</li> </ul>"},{"location":"kubernetes/edx.html#discuss-the-kubernetes-architecture","title":"Discuss the Kubernetes architecture.","text":"<ul> <li>1+ Master Nodes</li> <li>1+ Worker Nodes</li> <li>Distributed key-value store, like etcd</li> </ul> <ul> <li>If multiple Masters - only one in HA (High Availibility) mode.</li> <li>All Master nodes connect to etcd<ul> <li>etcd is a distributed key-value store.<ul> <li>KV store can be on Master, or separate with Master-KV connection.</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#explain-the-different-components-for-master-and-worker-nodes","title":"Explain the different components for master and worker nodes.","text":""},{"location":"kubernetes/edx.html#master","title":"Master","text":""},{"location":"kubernetes/edx.html#api-server","title":"API server","text":"<ul> <li>accepts REST commands</li> <li>validates &amp; processes commands</li> <li>After execution, state of cluster stored in distributed KV store.</li> </ul>"},{"location":"kubernetes/edx.html#scheduler","title":"Scheduler","text":"<ul> <li>schedules work to different worker nodes.</li> <li>resource usage information for each worker node.</li> <li>knows of user/operator-set constraints</li> <li>considers:<ul> <li>quality of the service requirements</li> <li>data locality</li> <li>affinity</li> <li>anti-affinity</li> <li>etc</li> </ul> </li> <li>schedules in terms of Pods and Services.</li> </ul>"},{"location":"kubernetes/edx.html#controller-manager","title":"Controller Manager","text":"<ul> <li>manages non-termination control loops which regulate Kubernetes cluster state.</li> <li>Each control loop knows desired state of objects under management, watches state through API server.</li> <li>If current state != desired state then it corrects</li> </ul>"},{"location":"kubernetes/edx.html#etcd","title":"etcd","text":"<ul> <li>distributed KV store</li> <li>stores cluster state</li> </ul>"},{"location":"kubernetes/edx.html#worker","title":"Worker","text":"<ul> <li>VM/Physical/etc running applications using Pods.</li> <li>Controlled by Master node.</li> <li>Pod is scheduling unit in k8s.</li> <li>Pod is logical connection of 1+ containers which are always scheduled together.</li> </ul>"},{"location":"kubernetes/edx.html#container-runtime","title":"Container runtime.","text":"<ul> <li>Ex: containerd; rkt; lxd</li> <li>Docker is a platform which uses containerd as a container runtime.</li> </ul>"},{"location":"kubernetes/edx.html#kubelet","title":"kubelet","text":"<ul> <li>on each worker node - communicates with master node</li> <li>receives Pod definition (primarily thru API server)</li> <li>runs containers associated with Pod; keeps containers healthy</li> <li> <p>connects to container runtime using Container Runtime Interface (CRI)</p> <ul> <li>CRI consists of protocol buffers, gRPC API, libraries</li> </ul> </li> <li> <p></p> </li> <li> <p>kubelet (grpc client) connects to CRI shim (grpc server) - performs container/image operations.</p> </li> <li>CRI two services:<ul> <li>ImageService<ul> <li>image-related operations.</li> </ul> </li> <li>RuntimeService<ul> <li>Pod &amp; container-related operations.</li> </ul> </li> <li>CRI allows k8s to use different container runtimes without need to recompile.</li> <li> <p>CRI Shims</p> <ul> <li> <p>dockershim</p> <ul> <li>containers created using Docker installed on worker nodes. Docker uses containerd to create/manage containers. </li> </ul> </li> <li> <p>cri-containerd</p> <ul> <li>containerd directly - no Docker. </li> </ul> </li> <li> <p>CRI-O</p> <ul> <li>enables using Open Container Initiative (OCI) compatibile runtimes.</li> <li>supports runC &amp; Clear Containers</li> <li>Any OCI-compliant runtime can be plugged-in. </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#kube-proxy","title":"kube-proxy","text":"<ul> <li>Services group related Pods &amp; load balances to them.</li> <li>network proxy on worker node</li> <li>listens to API server for Service endpoint creation/deletion.</li> <li>For each Service endpoint:<ul> <li>kube-proxy sets up the routes</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#discuss-about-cluster-state-management-with-etcd","title":"Discuss about cluster state management with etcd.","text":"<ul> <li>Stores cluster state.</li> <li>etcd is distributed Key-Value store based on Raft Concensus Algorithm<ul> <li>collection of machines work as group to survive failure of some members.</li> <li>one node will be master, rest followers. Any node can be treated as master.</li> <li>written in Go</li> <li>stores config details:<ul> <li>subnets; ConfigMaps; secrets; etc</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#review-the-kubernetes-network-setup-requirements","title":"Review the Kubernetes network setup requirements.","text":"<ul> <li> <p>A unique IP is assigned to each Pod</p> <ul> <li>Two Primary Specifications:<ul> <li>Container Network Model (CNM) - Docker</li> <li>Container Network Interface (CNI) - CoreOS</li> </ul> </li> <li>k8s uses CNI </li> <li>container runtime relies on CNI for IP assignment.</li> <li>CNI connects to underlying configured plugin (Bridge or MACvlan) to get IPs.</li> <li>Plugin passes IPs to CNI which passes IP back to container runtime.</li> </ul> </li> <li> <p>Containers in a Pod can communicate to each other</p> </li> <li>The Pod is able to communicate with other Pods in the cluster</li> <li>If configured, the application deployed inside a Pod is accessible from the external world.</li> <li>Container runtime creates isolated network for each container that it starts: network namespace<ul> <li>Can be shared across Containers or Host OS.</li> </ul> </li> <li>Inside Pod - containers share network namespace - can reach each other via localhost.</li> </ul> <p></p> <ul> <li>Pod-to-Pod Communication Across Nodes<ul> <li>Pods scheduled on any node.</li> <li>Pods need to communicate across nodes - all nodes should be able to reach any Pod.</li> <li>k8s ideal constraint: No Network Address Translation (NAT) during Pod-to-Pod communication across hosts</li> <li>^^ Achieved:<ul> <li>Routable Pods and nodes - uses underlying physical infrastructure like Google Kubernetes Engine.</li> <li>Software Defined Networking (Flannel; Weave; Calico; etc)</li> </ul> </li> <li>Kubernetes Cluster Networking documentation</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#ch4-installing-kubernetes","title":"Ch.4 Installing Kubernetes","text":""},{"location":"kubernetes/edx.html#discuss-about-the-different-kubernetes-configuration-options","title":"Discuss about the different Kubernetes configuration options.","text":""},{"location":"kubernetes/edx.html#all-in-one-single-node-installation","title":"All-in-One Single-Node Installation","text":"<p>With all-in-one, all the master and worker components are installed on a single node. This is very useful for learning, development, and testing. This type should not be used in production. Minikube is one such example, and we are going to explore it in future chapters.</p>"},{"location":"kubernetes/edx.html#single-node-etcd-single-master-and-multi-worker-installation","title":"Single-Node etcd, Single-Master, and Multi-Worker Installation","text":"<p>In this setup, we have a single master node, which also runs a single-node etcd instance. Multiple worker nodes are connected to the master node.</p>"},{"location":"kubernetes/edx.html#single-node-etcd-multi-master-and-multi-worker-installation","title":"Single-Node etcd, Multi-Master, and Multi-Worker Installation","text":"<p>In this setup, we have multiple master nodes, which work in an HA mode, but we have a single-node etcd instance. Multiple worker nodes are connected to the master nodes.</p>"},{"location":"kubernetes/edx.html#multi-node-etcd-multi-master-and-multi-worker-installation","title":"Multi-Node etcd, Multi-Master, and Multi-Worker Installation","text":"<p>In this mode, etcd is configured in a clustered mode, outside the Kubernetes cluster, and the nodes connect to it. The master nodes are all configured in an HA mode, connecting to multiple worker nodes. This is the most advanced and recommended production setup.</p>"},{"location":"kubernetes/edx.html#discuss-infrastructure-considerations-before-installing-kubernetes","title":"Discuss infrastructure considerations before installing Kubernetes.","text":"<ul> <li>Should we set up Kubernetes on bare metal, public cloud, or private cloud?</li> <li>Which underlying system should we use? Should we choose RHEL, CoreOS, CentOS, or something else?</li> <li>Which networking solution should we use?</li> <li>etc</li> </ul> <p>Choosing the right solution</p>"},{"location":"kubernetes/edx.html#discuss-infrastructure-choices-for-a-kubernetes-deployment","title":"Discuss infrastructure choices for a Kubernetes deployment.","text":""},{"location":"kubernetes/edx.html#localhost-installation","title":"Localhost Installation","text":"<ul> <li>Minikube</li> <li>Ubuntu on LXD</li> </ul>"},{"location":"kubernetes/edx.html#on-premise-installation","title":"On-Premise Installation","text":"<ul> <li>On-Premise VMs<ul> <li>k8s installed on VMs</li> <li>use Vagrant, VMware vSphere, KVM, etc</li> <li>Automate: Ansible / kubeadm</li> </ul> </li> <li>On-Premise Bare Metal<ul> <li>on top of OS<ul> <li>RHEL, CoreOS, Fedora, Ubuntu, etc</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#cloud-installation","title":"Cloud Installation","text":""},{"location":"kubernetes/edx.html#hosted-solutions","title":"Hosted Solutions","text":"<ul> <li>Google Kubernetes Engine (GKE)</li> <li>Azure Container Service (AKS)</li> <li>Amazon Elastic Container Service for k8s (EKS) - Currently in Tech Preview</li> <li>OpenShift Dedicated</li> <li>Platform9</li> <li>IBM Cloud Container Service</li> </ul>"},{"location":"kubernetes/edx.html#turnkey-cloud-solutions","title":"Turnkey Cloud Solutions","text":"<ul> <li>Google Compute Engine</li> <li>Amazon AWS</li> <li>Microsoft Azure</li> <li>Tectonic by CoreOS</li> </ul>"},{"location":"kubernetes/edx.html#bare-metal","title":"Bare Metal","text":"<ul> <li>Various Cloud providers allow Bare Metal installations.</li> </ul>"},{"location":"kubernetes/edx.html#review-kubernetes-installation-tools-and-resources","title":"Review Kubernetes installation tools and resources.","text":""},{"location":"kubernetes/edx.html#kubeadm","title":"kubeadm","text":"<ul> <li>first-class citizen in k8s ecosystem.</li> <li>secure/recommended bootstrap of k8s.</li> <li>Contains building blocks to setup cluster.</li> <li>Easily extendable to add functionality.</li> <li>Does not provision machines</li> </ul>"},{"location":"kubernetes/edx.html#kubespray","title":"KubeSpray","text":"<ul> <li>(formerly name: Kargo)</li> <li>Purpose: Install Highly Available k8s cluster on:<ul> <li>AWS, GCE, Azure, OpenStack, bare metal.</li> </ul> </li> <li>based on Ansible.</li> <li>Available on most Linux distributions.</li> <li>Kubernets Incubator Project</li> </ul>"},{"location":"kubernetes/edx.html#kops","title":"Kops","text":"<ul> <li>Create/Destroy/Upgrade/Maintain production-grade, HA, k8s clusters from CLI.</li> <li>Can provision machines.</li> <li>AWS officially supported.</li> <li>GCE / VMware vSphere in alpha stage.</li> <li>++platforms for future.</li> </ul> <p>Install k8s from scratch</p> <p>Kubernetes The Hard Way</p>"},{"location":"kubernetes/edx.html#ch5-setting-up-a-single-node-k8s-cluster-with-minikube","title":"Ch.5 Setting Up a Single-Node k8s Cluster with Minikube","text":""},{"location":"kubernetes/edx.html#discuss-minikube","title":"Discuss Minikube.","text":"<ul> <li>runsin VM on Linux/Mac/Windows.</li> <li>Requirements:<ul> <li>kubectl<ul> <li>binary used to access k8s cluster.</li> <li>Minikube requires kubectl installation to operate, but not to install.</li> </ul> </li> <li>On Linux:<ul> <li>VirtualBox or KVM hypervisors.</li> </ul> </li> <li>On macOS:<ul> <li>Hyperkit driver, xhyve driver, VirtualBox, or VMware Fusion hypervisors.</li> </ul> </li> <li>On Windows:<ul> <li>VirtualBox / Hyper-V hypervisors.</li> </ul> </li> <li>VT-x/AMD-v virtualization enabled in BIOS.</li> <li>Internet access on first run.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#install-minikube-on-linux-mac-and-windows","title":"Install Minikube on Linux, Mac, and Windows.","text":"<p>Start Here: Github Installation directions.</p>"},{"location":"kubernetes/edx.html#linux","title":"Linux","text":"<pre><code># Install VirtualBox\nsudo apt-get install virtualbox\n# Install Minikube\ncurl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.25.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/\n# Validate Minikube installation\nminikube start\nminikube status\nminikube stop\n</code></pre>"},{"location":"kubernetes/edx.html#mac","title":"Mac","text":"<p>Install VirtualBox on macOS</p> <pre><code># Install Minikube\ncurl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.25.0/minikube-darwin-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/\n# Validate Minikube installation\nminikube start\nminikube status\nminikube stop\n</code></pre>"},{"location":"kubernetes/edx.html#windows","title":"Windows","text":"<ul> <li> <p>Install VirtualBox</p> <ul> <li>Disable Hyper-V</li> <li>Windows support experimental</li> </ul> </li> <li> <p>Download the Minikube binary from the Distribution section.</p> <ul> <li>Add Minikube binary to $PATH.</li> </ul> </li> <li> <p>Set default VM driver for Minikube</p> </li> </ul> <pre><code>PS C:\\Windows\\system32&gt; minikube config set vm-driver virtualbox\n# These changes will take effect upon a minikube delete and then a minikube start\n</code></pre> <ul> <li>Validate Installation</li> </ul> <pre><code>PS C:\\WINDOWS\\system32&gt; minikube start\nPS C:\\WINDOWS\\system32&gt; minikube status\nPS C:\\WINDOWS\\system32&gt; minikube stop\n</code></pre>"},{"location":"kubernetes/edx.html#ch6-accessing-minikube","title":"Ch.6 Accessing Minikube","text":""},{"location":"kubernetes/edx.html#review-methods-to-access-any-kubernetes-cluster","title":"Review methods to access any Kubernetes cluster.","text":""},{"location":"kubernetes/edx.html#command-line-interface-cli","title":"Command Line Interface (CLI)","text":"<ul> <li>kubectl</li> </ul>"},{"location":"kubernetes/edx.html#graphical-user-interface-gui","title":"Graphical User Interface (GUI)","text":"<ul> <li>Kubernetes dashboard</li> </ul>"},{"location":"kubernetes/edx.html#apis","title":"APIs.","text":"<ul> <li>Three independent groups:<ul> <li>Core Group (/api/v1)<ul> <li>Pods, Services, nodes, etc</li> </ul> </li> <li>Named Group<ul> <li>objects in /apis/NAME/VERSION format</li> <li>API versions imply levels of stability/support:<ul> <li>Alpha - may be dropped @ any point in time, without notice.<ul> <li>Ex: /apis/batch/v2alpha1</li> </ul> </li> <li>Beta - well-tested; semantics of objects may change<ul> <li>Ex: /apis/certificates.k8s.io/v1beta1</li> </ul> </li> <li>Stable - appears in released software for many versions<ul> <li>Ex: /apis/networking.k8s.io/v1</li> </ul> </li> </ul> </li> </ul> </li> <li>System-wide<ul> <li>system-wide API endpoints<ul> <li>Ex: /healthz ; /logs ; /metrcs ; /ui ; etc</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#configure-kubectl-for-linux-macos-and-windows","title":"Configure kubectl for Linux, macOS, and Windows.","text":""},{"location":"kubernetes/edx.html#linux_1","title":"Linux","text":"<pre><code># Download latest stable kubectl binary\ncurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\n\n# Make kubectl executable\nchmod +x ./kubectl\n\n# Move into PATH\nsudo mv ./kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"kubernetes/edx.html#macos","title":"macOS","text":"<pre><code># Download latest stable kubectl binary\ncurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl\n\n# Make kubectl executable\nchmod +x ./kubectl\n\n# Move into PATH\nsudo mv ./kubectl /usr/local/bin/kubectl\n</code></pre> <p>OR using Brew:</p> <pre><code>brew install kubectl\n</code></pre>"},{"location":"kubernetes/edx.html#windows_1","title":"Windows","text":"<ul> <li> <p>DL latest kubectl release</p> </li> <li> <p>Depending on latest release, DL kubectl binary</p> </li> </ul> <pre><code># Example download 1.9.3\ncurl -LO https://storage.googleapis.com/kubernetes-release/release/v1.9.3/bin/windows/amd64/kubectl.exe`\n</code></pre> <ul> <li>Once downloaded - move kubectl binary to PATH</li> </ul>"},{"location":"kubernetes/edx.html#access-the-minikube-dashboard","title":"Access the Minikube dashboard.","text":"<pre><code>minikube dashboard\n</code></pre> <p>or</p> <p><pre><code>kubectl proxy\n</code></pre> - kubectl authenticates with API server on Master node - Makes dashboard available @ http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/kubernetes-dashboard:/proxy/#!/overview?namespace=default - kubernetes-dashboard service runs inside kube-system namespace.</p>"},{"location":"kubernetes/edx.html#access-minikube-via-apis","title":"Access Minikube via APIs.","text":""},{"location":"kubernetes/edx.html#with-kubectl-proxy","title":"With <code>kubectl proxy</code>","text":"<p><pre><code>kubectl proxy\n</code></pre> In a new session: <pre><code>curl http://localhost:8001\n</code></pre></p>"},{"location":"kubernetes/edx.html#without-kubectl-proxy","title":"Without <code>kubectl proxy</code>","text":"<ul> <li>Use Bearer Token &amp; kubectl<ul> <li>Def: access token generated by authentication server (API server on master node) and given to client</li> </ul> </li> </ul> <pre><code># Acquire Token\nTOKEN=$(kubectl describe secret -n kube-system $(kubectl get secrets -n kube-system | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d '\\t' | tr -d \" \")\n\n# Retrieve API server endpoint\nAPISERVER=$(kubectl config view | grep https | cut -f 2- -d \":\" | tr -d \" \")\n\n# Access API Server using curl\ncurl $APISERVER --header \"Authorization: Bearer $TOKEN\" --insecure\n</code></pre>"},{"location":"kubernetes/edx.html#ch7-kubernetes-building-blocks","title":"Ch.7 Kubernetes Building Blocks","text":""},{"location":"kubernetes/edx.html#review-the-kubernetes-object-model","title":"Review the Kubernetes object model.","text":"<ul> <li> <p>Object Model:</p> <ul> <li>what containerized apps are running on each node</li> <li>app resource consumption</li> <li>Policies attached to app (restart/upgrade, fault tolerance, etc)</li> </ul> </li> <li> <p>For each Object:</p> <ul> <li>dcl desired state using spec field.</li> <li>k8s manages status field for objects - state of object.</li> <li>k8s Control Plane always attempting to match desired state with actual state.</li> </ul> </li> <li> <p>Ex Objects:</p> <ul> <li>Pods, ReplicaSets, Deployments, Namespaces, etc</li> </ul> </li> <li> <p>To create Objects:</p> <ul> <li>Provide spec field to k8s API server.</li> <li>spec describes desired state &amp; basic info (name, etc)<ul> <li>JSON format</li> </ul> </li> <li>usually define object's definition in .yaml file<ul> <li>kubectl converts to JSON payload and sends to API server.</li> </ul> </li> </ul> </li> </ul> <p>TODO(Wes): Reduce     &gt; With the apiVersion field in the example above, we mention the API endpoint on the API server which we want to connect to. With the kind field, we mention the object type - in our case, we have Deployment. With the metadata field, we attach the basic information to objects, like the name. You may have noticed that in our example we have two spec fields (spec and spec.template.spec). With spec, we define the desired state of the deployment. In our example, we want to make sure that, at any point in time, at least 3 Pods are running, which are created using the Pods Template defined in spec.template. In spec.template.spec, we define the desired state of the Pod. Here, our Pod would be created using nginx:1.7.9.</p>"},{"location":"kubernetes/edx.html#discuss-labels-and-selectors","title":"Discuss Labels and Selectors.","text":"<ul> <li>Labels<ul> <li>key-value pairs attached to k8s objects (e.g. Pods).</li> <li>organize &amp; subset objects</li> <li>many objects -to- one label</li> <li>labels != unique to object</li> </ul> </li> </ul> <ul> <li> <p>Above Labels:</p> <ul> <li>app / env</li> </ul> </li> <li> <p>Label Selectors</p> <ul> <li>Equality-Based<ul> <li>filter objects on Label keys and values</li> <li><code>=</code>, <code>==</code>, <code>!=</code> operators</li> <li>Ex: env==dev</li> </ul> </li> <li>Set-Based<ul> <li>filter objects on set of values</li> <li><code>in</code>, <code>notin</code>, <code>exists</code> operators</li> <li>Ex: env in (dev, qa)</li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"kubernetes/edx.html#discuss-kubernetes-building-blocks","title":"Discuss Kubernetes building blocks","text":""},{"location":"kubernetes/edx.html#pods","title":"Pods","text":"<ul> <li>smallest k8s object.</li> <li>unit of deployment in k8s</li> <li>represents single instance of the app</li> <li>Pod is logical collection of 1+ containers, which:<ul> <li>Are scheduled together on the same host</li> <li>Share the same network namespace</li> <li>Mount the same external storage (volumes).</li> </ul> </li> </ul> <ul> <li>Ephemeral;</li> <li>can not self-heal<ul> <li>use with controllers<ul> <li>handle Pod's replication, fault tolerance, self-heal, etc</li> </ul> </li> </ul> </li> <li>Controller Ex:<ul> <li>Deployments, ReplicaSets, ReplicationControllers, etc</li> </ul> </li> <li>Pod Templates<ul> <li>attach Pod's specificiation to other objects</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#replicationcontroller-rc","title":"ReplicationController (rc)","text":"<ul> <li>part of master node's controller manager.</li> <li>assures specified # replicas for Pod are running.</li> <li>controllers like rc always used to create/manage Pods.</li> <li>only supports equality-based Selectors.</li> </ul>"},{"location":"kubernetes/edx.html#replicasets","title":"ReplicaSets","text":"<ul> <li>next generation ReplicationController</li> <li>support both equality- and set-based selectors</li> </ul> <p>One Pod dies, current state != desired state</p> <p></p> <p>ReplicaSet detects; creates Pod</p> <p></p> <p>ReplicaSets can be independent; mostly used by Deployments to orchestrate Pod creation, deletion, updates.</p>"},{"location":"kubernetes/edx.html#deployments","title":"Deployments","text":"<ul> <li>object</li> <li>automatically creates ReplicaSets.</li> <li>provides declarative updates to Pods and ReplicaSets.</li> <li>DeploymentController part of master node's controller manager.</li> <li>assures curret state == desired state.</li> <li>feature: Deployment recording (deployments explained below)<ul> <li>if something goes wrong - rollback to previous state</li> </ul> </li> </ul> <p>Below graphic:</p> <ul> <li>Deployment creates ReplicaSet A.</li> <li>ReplicaSet A creates 3 Pods.</li> <li>Each Pod - one container uses nginx:1.7.9.</li> </ul> <p></p> <p>Next graphic:</p> <ul> <li>in Deployment<ul> <li>we change Pods Template &amp; update image for nginx container to nginx:1.9.1.</li> <li>Pod Template modified: new ReplicaSet B created.</li> <li>process referred to as Deployment rollout.<ul> <li>rollout only triggered on Pods Template update for deployment.</li> </ul> </li> <li>Scaling operations do not trigger deployment.</li> </ul> </li> </ul> <p></p> <p>Next graphic:</p> <ul> <li>When ReplicaSet B ready:<ul> <li>Deployment points to it.</li> </ul> </li> </ul> <p></p>"},{"location":"kubernetes/edx.html#namespaces","title":"Namespaces","text":"<ul> <li>partitions k8s cluster.</li> <li>Ex: numerous users - organize into teams/projects.</li> <li>names of resources/objects created in Namespace are unique, but not across Namespaces.</li> </ul> <p>List all Namespaces: <pre><code>$ kubectl get namespaces\nNAME          STATUS       AGE\ndefault       Active       11h\nkube-public   Active       11h\nkube-system   Active       11h\n</code></pre></p> <ul> <li>k8s creates 2 default Namespaces:<ul> <li>kube-system<ul> <li>objects created by k8s system.</li> </ul> </li> <li>default<ul> <li>objects from any other Namespace.</li> </ul> </li> </ul> </li> <li>by default, we connect to default Namespace.</li> <li>kube-public<ul> <li>readable by all users.</li> <li>used for special purposes (Ex: bootstrapping a cluster).</li> </ul> </li> <li>Resource Quotas<ul> <li>divide cluster resources within Namespaces.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#ch8-authentication-authorization-admission-control","title":"Ch.8 Authentication, Authorization, Admission Control","text":"<p>Objective:</p> <ul> <li>Discuss authentication, authorization, and access control stages of the Kubernetes API access.</li> <li>Understand the different kinds of Kubernetes users.</li> <li>Discuss the different modules for authentication and authorization.</li> </ul>"},{"location":"kubernetes/edx.html#stages-of-k8s-api-access","title":"Stages of k8s API access","text":""},{"location":"kubernetes/edx.html#authentication","title":"Authentication","text":"<p>Logs in user.</p> <ul> <li>k8s does not have object user, or store usernames.</li> <li>k8s can use usernames for access control and request logging.</li> <li>Two kinds of users:<ul> <li>Normal Users<ul> <li>Managed outside k8s cluster<ul> <li>via independent services, Ex:<ul> <li>User/Client Certificates</li> <li>file listing usernames/passwords</li> <li>Google accounts</li> <li>etc</li> </ul> </li> </ul> </li> </ul> </li> <li>Service Accounts<ul> <li>in-cluster processes communicate with API server to perform operations.</li> <li>Most Service Account users auto-created via API server</li> <li>Can also create manually</li> <li>Service Account users tied to given Namespace<ul> <li>mounts respective credentials to communicate with API server as Secrets.</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#authentication-modules","title":"Authentication Modules","text":"<ul> <li> <p>Overview:</p> <ul> <li>Multiple authenticators can be enabled</li> <li>first module to successfully authenticate request short-circuits the evaluation.</li> <li>to be successful - enable at least 2 methods:<ul> <li>service account tokens authenticator</li> <li>user authenticator</li> </ul> </li> <li>k8s also supports anonymous requests, if configured</li> </ul> </li> <li> <p>Client Certificates</p> <ul> <li>enable w/reference to file w/1+ cert authorities<ul> <li>pass <code>--client-ca-file=SOMEFILE</code> option to API server.</li> <li>cert auths in file validate client certs presented to API server.</li> <li>Demo Video: </li> </ul> </li> </ul> </li> <li>Static Token File<ul> <li>pass file w/pre-defined bearer tokens<ul> <li>pass with <code>--token-auth-file=SOMEFILE</code> option to API server.</li> <li>these tokens last indefinitely.</li> <li>cannot change w/o restarting API server</li> </ul> </li> </ul> </li> <li>Bootstrap Tokens<ul> <li>alpha; used in bootstrapping new k8s cluster.</li> </ul> </li> <li>Static Password File<ul> <li>pass file w/basic authentication details<ul> <li>pass w/ <code>--basic-auth-file=SOMEFILE</code> option to API server.</li> <li>lasts indefinitely</li> <li>change w/API server restart</li> </ul> </li> </ul> </li> <li>Service Account Tokens<ul> <li>auto-enabled authenticator</li> <li>uses signed bearer tokens to verify requests</li> <li>tokens attached to Pods using ServiceAccount Admission Controller.<ul> <li>allows in-cluster processes to talk to API server.</li> </ul> </li> </ul> </li> <li>OpenID Connect Tokens<ul> <li>connect with OAuth 2 providers<ul> <li>Ex: Azure Active Directory, Salesforce, Google, etc</li> </ul> </li> </ul> </li> <li>Webhook Token Authentication<ul> <li>verification of bearer tokens offloaded to remote servce.</li> </ul> </li> <li>Keystone Password<ul> <li>pass <code>--experimental-keystone-url=&lt;AuthURL&gt;</code> option to API Server.<ul> <li>AuthURL is Keystone server endpoint.</li> </ul> </li> </ul> </li> <li>Authenticating Proxy<ul> <li>used to program additional authentication logic</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#authorization","title":"Authorization","text":"<p>Authorizes API requests.</p> <ul> <li>After Authentication, users send API requests to perform operations.</li> <li>API requests are Authorized</li> <li>API request attributes authorized:<ul> <li>user, group extra, Resource, Namespace, etc</li> <li>these attributes evaluated against policies.</li> <li>if evalualtion success - request allowed; otherwise denied.</li> </ul> </li> <li>Multiple Authorization modules/authorizers.</li> <li>1+ module can be configured for k8s cluster<ul> <li>each module checked in sequence</li> <li>if any authorizer approves/denies - that decision is returned immediately.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#authorization-modules","title":"Authorization Modules","text":"<ul> <li>Node Authorizer<ul> <li>authorizes API requests from kubelets</li> <li>authorizes kubelet's:<ul> <li>read operations for services, endpoints, nodes, etc</li> <li>write operators for nodes, pods, events, etc</li> </ul> </li> <li>Kubernetes documentation</li> </ul> </li> <li>Attribute-Based Access Control (ABAC) Authorizer<ul> <li>k8s grants access to API requests - combine policies with attributes.</li> <li>Ex: user nkhare can only read Pods in Namespace lfs158: <pre><code>{\n  \"apiVersion\": \"abac.authorization.kubernetes.io/v1beta1\",\n  \"kind\": \"Policy\",\n  \"spec\": {\n    \"user\": \"nkhare\",\n    \"namespace\": \"lfs158\",\n    \"resource\": \"pods\",\n    \"readonly\": true\n  }\n}\n</code></pre></li> <li>enable w/<code>--authorization-mode=ABAC</code> option to API server.<ul> <li>specify authorization policy: <code>--authorization-policy-file=PolicyFile.json</code></li> </ul> </li> <li>Kubernetes documentation</li> </ul> </li> <li>Webhook Authorizer<ul> <li>k8s offers authorization decisions to 3<sup>rd</sup>-party services</li> <li>enable: <code>--authorization-webhook-config-file=SOME_FILENAME</code><ul> <li>SOME_FILENAME: config of remote authorization service</li> </ul> </li> <li>Kubernetes documentation</li> </ul> </li> <li>Role-Based Access Control (RBAC) Authorizer<ul> <li>regulate access to resources based on user assigned roles<ul> <li>roles: users, service accounts, etc</li> </ul> </li> <li>enable: <code>--authorization-mode=RBAC</code> to API server.</li> <li>Kubernetes documentation</li> <li>roles assigned operations:<ul> <li>create, get, update, patch, etc</li> <li>operations known as \"verbs\"</li> </ul> </li> <li>Two kids of roles:<ul> <li>Role<ul> <li>grant access to resource within specific Namespace <pre><code>kind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: lfs158\n  name: pod-reader\nrules:\n- apiGroups: [\"\"] # \"\" indicates the core API group\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n</code></pre></li> <li>creates pod-reader role<ul> <li>access only to Pods of lfs158 Namespace.</li> </ul> </li> </ul> </li> <li>ClusterRole<ul> <li>grany access to resource with cluster-wide scope</li> </ul> </li> <li>Once Role is created - bind users with RoleBinding<ul> <li>RoleBinding<ul> <li>bind users to same namespace as a Role. <pre><code>kind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: pod-read-access\n  namespace: lfs158\nsubjects:\n- kind: User\n  name: nkhare\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre></li> <li>user nkhare access to read Pods of lfs158 Namespace.</li> </ul> </li> <li>ClusterRoleBinding<ul> <li>grant access to resources @ cluster-level and to all Namespaces.</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#admission-control","title":"Admission Control","text":"<p>Modules which modify/reject requests based on additional checks:</p> <ul> <li>Ex: Quota</li> </ul> <p></p> <ul> <li> <p>Granular access control policies</p> <ul> <li>allowing privledged containers, checking resource quota, etc</li> <li>Resource Controllers:<ul> <li>ResourceQuota, AlwaysAdmit, DefaultStorageClass, etc</li> <li>in effect only after API requests authenticated/authorized</li> </ul> </li> </ul> </li> <li> <p>enable admission controls:</p> <ul> <li>start k8s API server w/admission-control</li> <li>takes comma-delimited, ordered list of controller names</li> <li><code>--admission-control=NamespaceLifecyl,ResourceQuota,PodSecurityPolicy,DefaultStorageClass</code></li> <li>Kubernetes documentation</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#ch9-services","title":"Ch.9 Services","text":""},{"location":"kubernetes/edx.html#objective","title":"Objective:","text":"<ul> <li>Discuss the benefits of grouping Pods into Services to access an application.</li> <li>Explain the role of the kube-proxy daemon running on each worker node.</li> <li>Explore the Service discovery options available in Kubernetes.</li> <li>Discuss different Service types.</li> </ul>"},{"location":"kubernetes/edx.html#connecting-users-to-pods","title":"Connecting Users to Pods","text":"<ul> <li>IP's assigned dynamically - Pods are ephemeral.</li> </ul> <p>User/Client connected Pod dies - new Pod created. New Pod - New IP.</p> <p></p> <p>k8s provides Services</p> <ul> <li>higher level abstraction than IP.</li> <li>groups Pods and policy to access them.</li> <li>grouping via Labels and Selectors.</li> </ul>"},{"location":"kubernetes/edx.html#services","title":"Services","text":"<ul> <li>app keyword as Label.</li> <li>frontend &amp; db values for Pods</li> </ul> <ul> <li>Selectors (app==frontend &amp; app==db)</li> <li>groups into 2 logical groups:<ul> <li>1 w/3 Pods</li> <li>1 w/1 Pod</li> </ul> </li> <li>assign name to logical grouping: Service name.</li> <li>Ex:<ul> <li>Two Services:<ul> <li>frontend-svc<ul> <li>selector: app==frontend</li> </ul> </li> <li>db-svc<ul> <li>selector: app==db</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#service-object-example","title":"Service Object Example","text":"<pre><code>kind: Service\napiVersion: v1\nmetadata:\n  name: frontend-svc\nspec:\n  selector:\n    app: frontend\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 5000\n</code></pre> <p>Explain:</p> <ul> <li>Service: frontend-svc</li> <li>Selects Pods w/Label app==frontend</li> <li>Each Service receives IP address by default<ul> <li>routable only inside cluster</li> <li>In Example:<ul> <li>172.17.0.4 for frontend-svc Service</li> <li>172.17.0.5 for db-svc Service</li> </ul> </li> <li>IP address attached to Service known as ClusterIP for that Service.</li> </ul> </li> </ul> <p></p> <ul> <li>User/Client connects to service via IP.</li> <li>Service forwards traffic to one of attached Pods.<ul> <li>Service load balances while selecting the Pods for forwarding.</li> <li>can select Port to forward<ul> <li>Ex:<ul> <li>frontend-svc receives requests from user/client on Port 80.</li> <li>frontend-svc forwards to Pod on Port 5000.</li> </ul> </li> </ul> </li> <li>If no port designated:<ul> <li>Service forwards on same port received</li> </ul> </li> </ul> </li> <li>Service endpoint<ul> <li>tuple of Pods, IP, targetPort</li> <li>Ex:<ul> <li>frontend-svc has 3 endpoints:<ul> <li>10.0.1.3:5000</li> <li>10.0.1.4:5000</li> <li>10.0.1.5:5000</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#kube-proxy_1","title":"kube-proxy","text":"<ul> <li>worker nodes run daemon called kube-proxy<ul> <li>watches API server on master node for addition/removal of Services/endpoints.</li> <li>For each new Service, on each node, kube-proxy configures iptables to capture traffic for its ClusterIP &amp; forwards to one of the endpoints.</li> <li>When Service removed:<ul> <li>kube-proxy removes iptables rules on all nodes as well.</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#service-discovery","title":"Service Discovery","text":"<p>Two methods for discovering Services:</p> <ul> <li>Environment Variables<ul> <li>@Pod Start, kubelet daemon on node adds env variables in Pod for all active Services.</li> <li>Ex:<ul> <li>Service: redis-master;</li> <li>exposes port 6379</li> <li>ClusterIP 172.17.0.6</li> <li>then, new Pod: <pre><code>REDIS_MASTER_SERVICE_HOST=172.17.0.6\nREDIS_MASTER_SERVICE_PORT=6379\nREDIS_MASTER_PORT=tcp://172.17.0.6:6379\nREDIS_MASTER_PORT_6379_TCP=tcp://172.17.0.6:6379\nREDIS_MASTER_PORT_6379_TCP_PROTO=tcp\nREDIS_MASTER_PORT_6379_TCP_PORT=6379\nREDIS_MASTER_PORT_6379_TCP_ADDR=172.17.0.6\n</code></pre></li> </ul> </li> <li>Note: Pods will not have env variables for Services created after Pod creation.</li> </ul> </li> <li>DNS<ul> <li>most common; recommended.</li> <li>addon for DNS.</li> <li>creates DNS record for each Service<ul> <li>format: my-svc.my-namespace.svc.cluster.local</li> </ul> </li> <li>Services w/same Namespace can talk.<ul> <li>Ex:<ul> <li>Service: redis-master in my-ns Namespace.</li> <li>All Pods in same Namespace can reach redis Service by using its name: redis-master</li> <li>Pods from other Namespaces can reach redis-master Service, by:<ul> <li>Add respective Namespace as suffix: redis-master.my-ns.</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#servicetype","title":"ServiceType","text":"<ul> <li>Access scope decided by ServiceType - can be mentioned when creating Service.<ul> <li>Is the Service:<ul> <li>only accessible within the cluster?</li> <li>accessible from within the cluster and the external world?</li> <li>Maps to an external entity which resides outside the cluster?</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#clusterip","title":"ClusterIP","text":"<ul> <li>default ServiceType</li> <li>Service receives Virtual IP using ClusterIP.<ul> <li>assigned IP used for communicating w/Service</li> <li>accessible only within Cluster.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#nodeport","title":"NodePort","text":"<ul> <li>in addition to creating ClusterIP:<ul> <li>port range 30000-32767 mapped to respective Service, from all worker nodes.</li> <li>Ex:<ul> <li>mapped NodePort: 32233 for service frontend-svc</li> <li>connect to any worker node on 32233</li> <li>node redirects all traffic to ClusterIP - 172.17.0.4</li> </ul> </li> </ul> </li> <li>Default:<ul> <li>when expose NodePort =&gt; random port auto-selected by k8s Master from range 30000-32767.</li> <li>can assign specific port to avoid dynamic port value while creating service.</li> </ul> </li> </ul> <ul> <li>NodePort ServiceType can make Services accessible to external world.<ul> <li>end-user connects to worker nodes on specified port</li> <li>worker node forwards traffic to apps running inside cluster.</li> <li>admins can configure reverse proxy outside k8s cluster<ul> <li>map specific endpoint to respective port on worker nodes</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#loadbalancer","title":"LoadBalancer","text":"<ul> <li>NodePort &amp; ClusterIP Services automatically created<ul> <li>external load balancer will route to them</li> </ul> </li> <li>Services exposed @ static port on each worker node</li> <li>Service exposed externally w/underlying cloud provider's load balance feature.</li> </ul> <ul> <li>LoadBalancer ServiceType only works if:<ul> <li>underlying IaaS supports automatic creation of Load Balancers<ul> <li>and</li> </ul> </li> <li>support in k8s (GCP/AWS)</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#externalip","title":"ExternalIP","text":"<ul> <li>Service mapped to ExternalIP if it can route to one or more worker nodes.</li> <li>Traffic ingressed with ExternalIP (as destination IP) on Service port is routed to one of the Service endpoints.</li> </ul> <ul> <li>Note:<ul> <li>ExternalIPs not managed by k8s.</li> <li>cluster admins configure routing to map ExternalIP address to one of the nodes.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#externalname","title":"ExternalName","text":"<ul> <li>ExternalName special ServiceType<ul> <li>no Selectors</li> <li>does not define any endpoints</li> <li>when accessed within cluster:<ul> <li>returns CNAME record of externally configured Service.</li> </ul> </li> </ul> </li> <li>make externally configured Services (my-database.example.com) available inside cluster<ul> <li>requires just the name (like, my-database)</li> <li>available inside same Namespace</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#ch10-deploying-a-stand-alone-application","title":"Ch.10 Deploying a Stand-Alone Application","text":"<ul> <li>Objective:<ul> <li>Deploy an application from the dashboard.</li> <li>Deploy an application from a YAML file using kubectl.</li> <li>Expose a service using NodePort.</li> <li>Access the application from the external world.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#minikube-gui","title":"Minikube GUI","text":"<pre><code>minikube start\nminikube status\nminikube dashboard\n</code></pre> <ul> <li>Deploy webserver usign nginx:alpine image:<ul> <li>Dashboard:<ul> <li>click: CREATE</li> </ul> </li> </ul> </li> </ul> <ul> <li>Tab: CREATE AN APP</li> <li>Enter as seen:</li> </ul> <ul> <li>Click: DEPLOY</li> </ul>"},{"location":"kubernetes/edx.html#kubectl-cli","title":"kubectl CLI","text":"<pre><code>kubectl get deployments\nkubectl get replicasets\nkubectl get pods\n</code></pre>"},{"location":"kubernetes/edx.html#labels-selectors","title":"Labels / Selectors","text":"<pre><code>kubectl describe pod webserver-74d8bd488f-xxxxx\nkubectl get pods -L k8s-app,label2\n# -L option = add additional columns in output\n\nkubectl get pods -l k8s-app=webserver\n# -l option = selector\n</code></pre>"},{"location":"kubernetes/edx.html#delete-deployment","title":"Delete Deployment","text":"<pre><code>kubectl delete deployments webserver\n# Also deletes ReplicaSets &amp; Pods\n</code></pre>"},{"location":"kubernetes/edx.html#deployment-yaml","title":"Deployment YAML","text":"<ul> <li>Create webserver.yaml</li> </ul> <pre><code># webserver.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webserver\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:alpine\n        ports:\n        - containerPort: 80\n</code></pre> <pre><code>kubectl create -f webserver.yaml\n</code></pre>"},{"location":"kubernetes/edx.html#create-expose-wnodeport","title":"Create / Expose w/NodePort","text":"<ul> <li>ServiceTypes: define access method for given Service.</li> <li>With NodePort ServiceType k8s opens static port on all worker nodes.<ul> <li>Connect to open static port from any node - forwarded to respective Service.</li> </ul> </li> </ul> <p>Create webserver-svc.yaml:</p> <p><pre><code># webserver-svc.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-service\n  labels:\n    run: web-service\nspec:\n  type: NodePort\n  ports:\n  - port: 80\n    protocol: TCP\n  selector:\n    app: nginx\n</code></pre> <pre><code>kubectl create -f webserver-svc.yaml\n</code></pre> <pre><code>kubectl get svc\nNAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nkubernetes    ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        4d\nweb-service   NodePort    10.108.132.106   &lt;none&gt;        80:31791/TCP   3m\n</code></pre></p> <ul> <li>ClusterIP: 10.108.132.106</li> <li>Port: 80:31791<ul> <li>We've reserved static port 31791 on node.</li> <li>If connect to node on that port - request forwarded to ClusterIP on port 80.</li> </ul> </li> </ul> <p>Deployment / Service creation can happen in any order.</p> <pre><code>kubectl describe svc web-service\n</code></pre> <p>web-service uses app=nginx as Selector, which selects the three Pods - listed as endpoints. So, whenever a request is sent to our Service - served by one of Pods listed in Endpoints section.</p>"},{"location":"kubernetes/edx.html#access-app-using-exposed-nodeport","title":"Access App Using Exposed NodePort","text":"<pre><code>minikube ip\n</code></pre> <p>Open browser @ listed IP and <code>kubectl describe svc web-service</code> NodePort.</p> <p>or, at CLI:</p> <pre><code>minikube service web-service\n</code></pre>"},{"location":"kubernetes/edx.html#liveness-readiness-probes","title":"Liveness / Readiness Probes","text":"<p>Kubernetes documentation</p> <ul> <li>Liveness Probe<ul> <li>checks application health<ul> <li>if fails - restarts container</li> </ul> </li> <li>Set by Defining:<ul> <li>Liveness Command</li> <li>Liveness HTTP request</li> <li>TCP Liveness Probe</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#liveness-command","title":"Liveness Command","text":"<ul> <li>Check existence of file /tmp/healthy:</li> </ul> <p><pre><code># liveness-exec.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-exec\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/busybox\n    args:\n    - /bin/sh\n    - -c\n    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 3\n      periodSeconds: 5\n</code></pre> <pre><code>kubectl create -f liveness-exec.yaml\nkubectl get pods\nkubectl describe pod liveness-exec\n</code></pre> - periodSeconds: tmp/healthy checked every 5 seconds. - initialDelaySeconds: requests kubelet to wait 3 seoncds before first probe.</p>"},{"location":"kubernetes/edx.html#liveness-http-request","title":"Liveness HTTP Request","text":"<ul> <li>kubelet sends HTTP GET request to /healthz endpoint of application on port 8080.</li> </ul> <pre><code># liveness-http.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-exec\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/busybox\n    args:\n    - /bin/sh\n    - -c\n    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: X-Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n</code></pre>"},{"location":"kubernetes/edx.html#tcp-liveness-probe","title":"TCP Liveness Probe","text":"<ul> <li>kubelet attempts to open TCP socket to the container running application.</li> </ul> <pre><code># liveness-tcp.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-exec\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/busybox\n    args:\n    - /bin/sh\n    - -c\n    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600\n    livenessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 15\n      periodSeconds: 20\n</code></pre>"},{"location":"kubernetes/edx.html#readiness-probes","title":"Readiness Probes","text":"<p>Application must meet conditions before receiving traffic.</p> <pre><code># readiness-probe.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: readiness\n  name: readiness-exec\nspec:\n  containers:\n  - name: readiness\n    image: k8s.gcr.io/busybox\n    args:\n    - /bin/sh\n    - -c\n    - sleep 20; touch /tmp/healthy; sleep 20; rm -rf /tmp/healthy; sleep 600\n    readinessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 5\n      periodSeconds: 5\n</code></pre>"},{"location":"kubernetes/edx.html#ch11-kubernetes-volume-management","title":"Ch.11 Kubernetes Volume Management","text":"<ul> <li>Explain the need for persistent data management.</li> <li>Discuss Kubernetes Volume and its types.</li> <li>Discuss PersistentVolumes and PersistentVolumeClaims.</li> </ul>"},{"location":"kubernetes/edx.html#volumes","title":"Volumes","text":"<p>Containers, and their data, are ephemeral.  Solve with Volumes.</p> <p></p> <ul> <li>Volume attached to a Pod, shared among containers in Pod.</li> <li>Volume has same life span as Pod.<ul> <li>Outlives containers of Pod.</li> <li>Data preserved across container restart.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#volume-types","title":"Volume Types","text":"<p>Directory mounted in Pod backed by underlying Volume Type - decides properties of directory (size, content, etc).</p> <ul> <li>emptyDir<ul> <li>empty Volume created for Pod as soon as it's scheduled on worker node.</li> <li>Volume life coupled with Pod.</li> <li>Pod dies - content of emptyDir deleted.</li> </ul> </li> <li>hostPath<ul> <li>share a directory from the host to Pod.</li> <li>Pod dies - content of Volume available on host.</li> </ul> </li> <li>gcePersistentDisk<ul> <li>mount Google Compute Engine (GCE) persistent disk into Pod.</li> </ul> </li> <li>awsElasticBlockStore<ul> <li>mount AWS EBS Volume into Pod.</li> </ul> </li> <li>nfs<ul> <li>mount NFS share into Pod.</li> </ul> </li> <li>iscsi<ul> <li>mount iSCSI share into Pod.</li> </ul> </li> <li>secret<ul> <li>pass sensitive information (passwords) to Pods.</li> </ul> </li> <li>persistentVolumeClaim<ul> <li>attach PersistentVolume to Pod.</li> </ul> </li> </ul> <p>Kubernetes Volume Types</p>"},{"location":"kubernetes/edx.html#persistent-volumes","title":"Persistent Volumes","text":"<p>Network-attached storage in the cluster - provisioned by admin.</p> <ul> <li>PersistentVolume (PV) subsystem<ul> <li>provides APIs for users/admins to manage / consume storage.</li> <li>Manage: PersistentVolume API resource type.</li> <li>Consume: PersistentVolumeClaim API resource type.</li> </ul> </li> </ul> <p></p> <ul> <li>PersistentVolumes can be dynamically provisioned based on StorageClass resource.</li> <li>StorageClass contains pre-defined provisioners and parameters to create a PersistentVolume.</li> <li>Using PersistentVolumeClaims:<ul> <li>User sends request for dynamic PV creation.<ul> <li>wired to StorageClass resource.</li> </ul> </li> </ul> </li> <li>Volume Types that support managing using PersistentVolumes:<ul> <li>GCEPersistentDisk</li> <li>AWSElasticBlockStore</li> <li>AzureFile</li> <li>NFS</li> <li>iSCSI</li> <li>Complete List: Kubernetes Documentation</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#persistentvolumeclaims","title":"PersistentVolumeClaims","text":"<ul> <li>PersistentVolumeClaim (PVC) is user request for storage.</li> <li>User requests for PersistentVolume resources based on size, access models, etc.</li> <li>Once suitable PersistentVolume is found:<ul> <li>bound to a PersistentVolumeClaim.</li> </ul> </li> </ul> <p>After successful bound, PersistentVolumeClaim resource can be used in Pod.</p> <p></p> <p>When finished - attached PersistentVolumes can be released, reclaimed, recycled.</p> <p>See Kubernetes Documentation.</p>"},{"location":"kubernetes/edx.html#container-storage-interface-csi","title":"Container Storage Interface (CSI)","text":"<ul> <li>Container orchestrators (k8s, Mesos, Docker, etc) each have unqiue method of managing external storage using Volumes.</li> <li>Storage Vendors can't keep up with differences.<ul> <li>Let's standardize!<ul> <li>Container Storage Interface specifications.</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#ch12-deploying-a-multi-tier-application","title":"Ch.12 Deploying a Multi-Tier Application","text":"<ul> <li>Analyze a sample multi-tier application.</li> <li>Deploy a multi-tier application.</li> <li>Scale an application.</li> </ul>"},{"location":"kubernetes/edx.html#rsvp-application","title":"RSVP Application","text":"<ul> <li>users register for event.<ul> <li>provide username/email.</li> </ul> </li> <li>name/email goes in table.</li> <li>App:<ul> <li>backend database: MongoDB</li> <li>frontend: Python Flask-based</li> </ul> </li> </ul> <p>Code: github - rsvp.py     - look for MONGODB_HOST env variable for db endpoint.     - connect to it on port 27017</p> <pre><code>MONGODB_HOST=os.environ.get('MONGODB_HOST', 'localhost')\nclient = MongoCLient(MONGODB_HOST, 27017)\n</code></pre> <ul> <li>Deploy with 1 backend / 1 frontend</li> <li>then, scale</li> </ul>"},{"location":"kubernetes/edx.html#backend","title":"Backend","text":"<pre><code># rsvp-db.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rsvp-db\n  labels:\n    appdb: rsvpdb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      appdb: rsvpdb\n  template:\n    metadata:\n      labels:\n        appdb: rsvpdb\n    spec:\n      containers:\n      - name: rsvp-db\n        image: mongo:3.3\n        ports:\n        - containerPort: 27017\n</code></pre> <pre><code>kubectl create -f rsvp-db.yaml\n</code></pre> <p>Create mongodb service.</p> <p><pre><code># rsvp-db-service.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: mongodb\n  labels:\n    app: rsvpdb\nspec:\n  ports:\n  - port: 27017\n    protocol: TCP\n  selector:\n    appdb: rsvpdb\n</code></pre> <pre><code>kubectl create -f rsvp-db-service.yaml\n</code></pre></p> <ul> <li>did not specify ServiceType<ul> <li>mongodb has default ClusterIP ServiceType.</li> <li>mongodb will not be accessible from external world.</li> </ul> </li> </ul> <pre><code>kubectl get deployments\n</code></pre> <pre><code>kubectl get services\n</code></pre>"},{"location":"kubernetes/edx.html#frontend","title":"Frontend","text":"<ul> <li>using Python Flask-based microframework<ul> <li>source: https://raw.githubusercontent.com/cloudyuga/rsvpapp/master/rsvp.py</li> <li>Docker image: teamcloudyuga/rsvpapp</li> <li>Dockerfile to create teamcloudyuga/rsvpapp: https://raw.githubusercontent.com/cloudyuga/rsvpapp/master/Dockerfile</li> </ul> </li> </ul> <p>Create Deployment for rsvp Frontend.</p> <pre><code># rsvp-web.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rsvp\n  labels:\n    app: rsvp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rsvp\n  template:\n    metadata:\n      labels:\n        app: rsvp\n    spec:\n      containers:\n      - name: rsvp-app\n        image: teamcloudyuga/rsvpapp\n        env:\n        - name: MONGODB_HOST\n          value: mongodb\n        ports:\n        - containerPort: 5000\n          name: web-port\n</code></pre> <pre><code>kubectl create -f rsvp-web.yaml\n</code></pre> <ul> <li>passing name of MongoDB Service, mongodb, as env variable.<ul> <li>expected by frontend</li> </ul> </li> <li>Note Ports:<ul> <li>containerPort 5000</li> <li>name: web-port</li> <li>Can change underlying containerPort without making changes Service.</li> </ul> </li> </ul> <p>Create Service for rsvp Frontend.</p> <pre><code># rsvp-web-service.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: rsvp\n  labels:\n    app: rsvp\nspec:\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort: web-port\n    protocol: TCP\n  selector:\n    app: rsvp\n</code></pre> <pre><code>kubectl create -f rsvp-web-service.yaml\n</code></pre> <ul> <li>Note:<ul> <li>targetPort in ports section.<ul> <li>forwards requests on port 80 for ClusterIP to web-port port (5000) on connected Pods.</li> </ul> </li> </ul> </li> </ul> <p>Look @ available deployments and services:</p> <pre><code>kubectl get deployments\nkubectl get services\n</code></pre>"},{"location":"kubernetes/edx.html#access-rsvp-application","title":"Access RSVP Application","text":"<p><pre><code>minikube ip\n# NodePort Port\nkubectl get services\n</code></pre> OR <pre><code>minikube service rsvp\n</code></pre></p> <p></p>"},{"location":"kubernetes/edx.html#scale-frontend","title":"Scale Frontend","text":"<p>Scale from 1 to 4 replicas:</p> <pre><code>kubectl scale deployment rsvp --replicas=3\nkubectl get deployments\n</code></pre> <p>Refreshing site will show multiple Host: rsvp-xxx-xxx as routed to different endpoints.</p>"},{"location":"kubernetes/edx.html#ch13-configmaps-and-secrets","title":"Ch.13 ConfigMaps and Secrets","text":"<ul> <li>Discuss configuration management for applications in Kubernetes using ConfigMaps.</li> <li>Share sensitive data (such as passwords) using Secrets.</li> </ul>"},{"location":"kubernetes/edx.html#configmaps","title":"ConfigMaps","text":"<ul> <li>decouples config details from container image.</li> <li>pass as key-value pairs<ul> <li>later consumed by Pods, controllers, other system components, etc.</li> </ul> </li> <li>Create by:<ul> <li>literal value</li> <li>files</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#create-configmap-cli","title":"Create ConfigMap @ CLI","text":"<pre><code>kubectl create configmap my-config --from-literal=key1=value1 --from-literal=key2=value2\n</code></pre>"},{"location":"kubernetes/edx.html#get-configmap-details","title":"Get ConfigMap Details","text":"<pre><code>kubectl get configmaps my-config -o yaml\n</code></pre>"},{"location":"kubernetes/edx.html#create-configmap-from-file","title":"Create ConfigMap from file.","text":"<pre><code># customer1-configmap.yaml\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: customer1\ndata:\n  TEXT1: Customer1_Company\n  TEXT2: Welcomes You\n  COMPANY: Customer1 Company Technology Pct. Ltd.\n</code></pre> <pre><code>kubectl create -f customer1-configmap.yaml\n</code></pre>"},{"location":"kubernetes/edx.html#use-configmap-in-pods","title":"Use ConfigMap in Pods","text":"<p>While creating deployment - assign values for env variables from customer1 ConfigMap:</p> <pre><code># container\n....\n  containers:\n      - name: rsvp-app\n        image: teamcloudyuga/rsvpapp\n        env:\n        - name: MONGODB_HOST\n          value: mongodb\n        - name: TEXT1\n          valueFrom:\n            configMapKeyRef:\n              name: customer1\n              key: TEXT1\n        - name: TEXT2\n          valueFrom:\n            configMapKeyRef:\n              name: customer1\n              key: TEXT2\n        - name: COMPANY\n          valueFrom:\n            configMapKeyRef:\n              name: customer1\n              key: COMPANY\n....\n</code></pre> <ul> <li>TEXT1 env var: \"Customer1_Company\"</li> <li>TEXT2 env var: \"Welcomes You\"</li> </ul>"},{"location":"kubernetes/edx.html#mount-configmap-as-volume","title":"Mount ConfigMap as Volume","text":"<ul> <li>Kubernetes documentation on ConfigMaps.</li> <li>For Each key:<ul> <li>file in mount path is key</li> <li>content of file becomes value</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#secrets","title":"Secrets","text":"<ul> <li>Shares sensitive info (pws, tokens, keys)</li> <li>passed as key-value pairs</li> <li>Secret objects are referenced in Deployments.</li> <li>Secret data stored as plain text inside etcd.</li> </ul> <pre><code>kubectl create secret generic my-password --from-literal=password=my3q1p@ssw0rd\n</code></pre> <pre><code>kubectl get secret my-password\nkubectl describe secret my-password\n</code></pre>"},{"location":"kubernetes/edx.html#create-secret-manually","title":"Create Secret Manually","text":"<p>With Secrets, each object must be encoded using base64.</p> <pre><code>echo mysqlpassword | base64\n</code></pre> <p>Use base64 encoded password in config file:</p> <pre><code># my-password.yaml\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: my-password\ntype: Opaque\ndata:\n  password: bXlzcWxwYXNzd29yZAo=\n</code></pre> <p>base64 != encryption:</p> <pre><code>echo \"bXlzcWxwYXNzd29yZAo=\" | base64 --decode\n</code></pre>"},{"location":"kubernetes/edx.html#use-secrets-inside-pods","title":"Use Secrets Inside Pods","text":"<ul> <li>expose as env variable<ul> <li>or</li> </ul> </li> <li>mount as data volume</li> </ul>"},{"location":"kubernetes/edx.html#environment-variable","title":"Environment Variable","text":"<p>Reference a Secret &amp; assign value of its key as env variable WORDPRESS_DB_PASSWORD:</p> <pre><code>.....\n    spec:\n      containers:\n      - image: wordpress:4.7.3-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: wordpress-mysql\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: my-password\n              key: password\n.....\n</code></pre>"},{"location":"kubernetes/edx.html#mount-as-volume","title":"Mount as Volume","text":"<ul> <li>Secrets as Files from Pod:<ul> <li>mount Secret as Volume inside Pod.</li> <li>file created for each key in Secret<ul> <li>contents = value</li> </ul> </li> </ul> </li> </ul> <p>Kubernetes documentation</p>"},{"location":"kubernetes/edx.html#ch14-ingress","title":"Ch.14 Ingress","text":"<ul> <li>Objective:<ul> <li>Explain what Ingress and Ingress Controllers are.</li> <li>Learn when to use Ingress.</li> <li>Access an application from the external world using Ingress.</li> </ul> </li> </ul> <p>Ingress allows updates to app w/o worrying about external access.</p> <p>\"An Ingress is a collection of rules that allow inbound connections to reach the cluster Services.\"</p> <ul> <li>Ingress configures Layer 7 HTTP load balancer for Services.</li> <li>Provides:<ul> <li>TLS (Transport Layer Security)</li> <li>Name-based virtual hosting</li> <li>Path-based routing</li> <li>Custom roles</li> </ul> </li> </ul> <p></p> <ul> <li>Users don't connect directly to Service.</li> <li>Users reach Ingress endpoint, forwarded to respective Service.</li> </ul> <pre><code># webserver-ingress.yaml\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: web-ingress\n  namespace: default\nspec:\n  rules:\n  - host: blue.example.com\n    http:\n      paths:\n      - backend:\n          serviceName: webserver-blue-svc\n          servicePort: 80\n  - host: green.example.com\n    http:\n      paths:\n      - backend:\n          serviceName: webserver-green-svc\n          servicePort: 80\n</code></pre> <ul> <li> <p>Above, Example of Name-Based Virtual Hosting Ingress rule:</p> <ul> <li>User requests to both blue.example.com &amp; green.example.com routed to same Ingress endpoint.</li> <li>forwarded to webserver-blue-svc &amp; webserver-green-svn, respectively.</li> </ul> </li> <li> <p>Below, Example of Fan Out Ingress rules:</p> <ul> <li>requests: example.com/blue &amp; example.com/green</li> <li>forwarded: webserver-blue-svc &amp; webserver-green-svc, respectively.</li> </ul> </li> </ul> <p></p>"},{"location":"kubernetes/edx.html#ingress-controller","title":"Ingress Controller","text":"<ul> <li>Ingress Controller watches Master Node's API server for changes in Ingress resources<ul> <li>updates Layer 7 Load Balancer accordingly.</li> </ul> </li> <li>k8s has several Ingress Controllers:<ul> <li>GCE L7 Load Balancer</li> <li>Nginx Ingress Controller</li> <li>can also build your own</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#start-ingress-controller-wminikube","title":"Start Ingress Controller w/Minikube","text":"<p>Minikube v0.14.0+ contains Nginx Ingress Controller setup as addon:</p> <pre><code>minikube addons enable ingress\n</code></pre>"},{"location":"kubernetes/edx.html#deploy-ingress-resource","title":"Deploy Ingress Resource","text":"<pre><code># webserver-ingress.yaml\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: web-ingress\n  namespace: default\nspec:\n  rules:\n  - host: blue.example.com\n    http:\n      paths:\n      - backend:\n          serviceName: webserver-blue-svc\n          servicePort: 80\n  - host: green.example.com\n    http:\n      paths:\n      - backend:\n          serviceName: webserver-green-svc\n          servicePort: 80\n</code></pre> <pre><code>kubectl create -f webserver-ingress.yaml\n</code></pre>"},{"location":"kubernetes/edx.html#access-services-using-ingress","title":"Access Services Using Ingress","text":"<ul> <li>Should now have access to:<ul> <li>webserver-blue-svc &amp; webserver-green-svc<ul> <li>via</li> </ul> </li> <li>blue.example.com &amp; green.example.com</li> </ul> </li> </ul> <p>Setup on Minikube (local VM), update host config file (/etc/hosts on Mac/Linux):</p> <pre><code>minikube ip\n192.168.99.100\n\ncat /etc/hosts\n127.0.0.1        localhost\n::1              localhost\n192.168.99.100   blue.example.com green.example.com\n</code></pre>"},{"location":"kubernetes/edx.html#ch15-advanced-topics","title":"Ch.15 Advanced Topics","text":""},{"location":"kubernetes/edx.html#annotations","title":"Annotations","text":"<ul> <li>Attach arbitrary non-identifying metadata to any objects, K-V</li> </ul> <pre><code>\"annotations\": {\n  \"key1\" : \"value1\",\n  \"key2\" : \"value2\"\n}\n</code></pre> <ul> <li>Not used to ID/select objects, instead:<ul> <li>Store buid/release IDs, PR numbers, git branch ,etc</li> <li>Phone/pager numbers of people responsible, directory entries specifying where that info can be found</li> <li>Pointers to logging, monitoring, analytics, audit repositories, debugging tools, etc.</li> <li>Etc</li> </ul> </li> </ul> <p>Ex: While Create Deployment, add description like:</p> <pre><code>apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: webserver\n  annotations:\n    description: Deployment based PoC dates 2nd June'2017\n....\n</code></pre> <p>Look @ annotations while describing object:</p> <pre><code>kubectl describe deployment webserver\nName:                webserver\nNamespace:           default\nCreationTimestamp:   Sat, 03 Jun 2017 05:10:38 +0530\nLabels:              app=webserver\nAnnotations:         deployment.kubernetes.io/revision=1\n                     description=Deployment based PoC dates 2nd June'2017\n...\n</code></pre>"},{"location":"kubernetes/edx.html#deployment-features","title":"Deployment Features","text":"<p>Record Deployment, revert if wrecks.</p> <p></p> <p>If recorded Deployment before update, revert back to known working state:</p> <p></p> <ul> <li>Deployment Object also provides:<ul> <li>Autoscaling</li> <li>Proportional scaling</li> <li>Pausing and resuming.</li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#jobs","title":"Jobs","text":"<ul> <li>Creates 1+ Pods to perform task.</li> <li>Job object takes responsibility of Pod failures.</li> <li>Assures task completed successfully.</li> <li>Task complete - Pods terminate automatically.</li> <li>Can be scheduled for times/dates. CronJob</li> </ul>"},{"location":"kubernetes/edx.html#quota-management","title":"Quota Management","text":"<ul> <li>ResourceQuota object.</li> <li>Provides contraints that limit aggregate resource consumption per Namespace.</li> <li>Types of Quotas per Namespace:<ul> <li>Compute Resource Quota<ul> <li>limit total sum of compute resources (CPU, memory, etc) which can be requested in Namespace.</li> </ul> </li> <li>Storage Resource Quota<ul> <li>Limit sum of storage resources (PersistentVolumeClaims, requests.storage, etc).</li> </ul> </li> <li>Object Count Quota<ul> <li>Restrict # objects of given type (Pods, ConfigMaps, PersistentVolumeClaims, ReplicationControllers, Services, Secrets, etc).</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#daemonsets","title":"DaemonSets","text":"<ul> <li>DaemonSet object allows:<ul> <li>collecting monitoring data from all nodes.</li> <li>running storage daemon on all nodes.</li> <li>etc.</li> <li>specific type of Pod running on all nodes at all times.</li> </ul> </li> <li>When Node added to Cluster:<ul> <li>Pod from given DaemonSet created on it.</li> </ul> </li> <li>When Node dies<ul> <li>Respective Pods garbage collected.</li> </ul> </li> <li>If DaemonSet deleted - all Pods it created are deleted as well.</li> </ul>"},{"location":"kubernetes/edx.html#statefulsets","title":"StatefulSets","text":"<ul> <li>StatefulSet controller used for apps requiring unique identity:<ul> <li>name</li> <li>network identifications</li> <li>strict ordering</li> <li>etc, Ex:<ul> <li>MySQL cluster, etcd cluster</li> </ul> </li> </ul> </li> <li>Provides ID and guaranteed ordering of deployment and scaling of Pods.</li> </ul>"},{"location":"kubernetes/edx.html#kubernetes-cluster-federation","title":"Kubernetes Cluster Federation","text":"<ul> <li>Manage multiple k8s clusters from single control plane.</li> <li>Sync resources across clusters &amp; cross-cluster discovery.</li> <li>Allows Deployments across regions, and access using global DNS record.</li> <li>Useful w/hybrid solutions:<ul> <li>Cluster inside private datacenter.<ul> <li>and</li> </ul> </li> <li>Cluster on public cloud.</li> </ul> </li> <li>Can assign weights for each cluster in the Federation - distribute load.</li> </ul>"},{"location":"kubernetes/edx.html#custom-resources","title":"Custom Resources","text":"<ul> <li>A resource is an API endpoint which stores a collection of API objects.<ul> <li>Ex: Pod resource contains all Pod objects.</li> </ul> </li> <li>k8s existing resources fullfill most requirements.</li> <li>Can create new resources using custom resources<ul> <li>dynamic in nature<ul> <li>appear/disappear in already running cluster @ anytime.</li> </ul> </li> </ul> </li> <li>Make resource declarative:<ul> <li>create/install custom controller<ul> <li>interprets resource structure</li> <li>performs required actions</li> <li>can be deployed/managed in pre-running clusters</li> </ul> </li> </ul> </li> <li>Two Methods to Add Custom Resources:<ul> <li>Custom Resource Definitions (CRDs)<ul> <li>Easiest</li> <li>doesn't require programming knowledge</li> <li>building custom controller would require some programming</li> </ul> </li> <li>API Aggregation<ul> <li>Fine grained control</li> <li>subordinate API servers</li> <li>sit behind primary API server &amp; act as proxy</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#helm","title":"Helm","text":"<ul> <li>k8s manifests:<ul> <li>Deployments</li> <li>Services</li> <li>Volume Claims</li> <li>Ingress</li> <li>etc</li> </ul> </li> <li>Chart<ul> <li>Can bundle manifests after templatizing them into well-defined format, along with other metadata.</li> <li>can be served via repositories<ul> <li>like rpm &amp; deb packages.</li> </ul> </li> </ul> </li> <li>Helm:<ul> <li>Package manager (like yum &amp; apt) for k8s.</li> <li>install/update/delete Charts in k8s cluster.</li> <li>Two components:<ul> <li>Client - Helm - runs on user's workstation.</li> <li>Server - tiller - runs inside k8s cluster.</li> <li>Client helm connects to server tiller to manage Charts.</li> </ul> </li> </ul> </li> <li>Github Helm Charts</li> </ul>"},{"location":"kubernetes/edx.html#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>Collect resource usage data by Pods, Services, nodes, etc to determine scaling decisions.</p> <ul> <li>Heapster<ul> <li>cluster-wide aggregator of monitoring &amp; event data</li> <li>native k8s support</li> </ul> </li> <li>Prometheus<ul> <li>part of CNCF</li> <li>can be used to gather resource usage from k8s components and objects.</li> <li>Using client libraries - can instrument code of app.</li> </ul> </li> </ul> <p>Logging important for debugging - collected from objects, nodes, etc.</p> <ul> <li>Elasticsearch<ul> <li>Uses fluentd w/custom config as an agent on nodes.<ul> <li>open source data collector.</li> <li>part for CNCF.</li> </ul> </li> </ul> </li> </ul>"},{"location":"kubernetes/edx.html#ch16-community","title":"Ch.16 Community","text":"<ul> <li>Understand the importance of Kubernetes community.</li> <li>Learn about the different channels to interact with the Kubernetes community.</li> <li>List major CNCF events.</li> </ul> <p>K8sPort     - recognizes / rewards community members</p> <ul> <li>Weekly Meetings using video conference tools.<ul> <li>https://groups.google.com/forum/#!forum/kubernetes-community-video-chat</li> </ul> </li> <li>Meetup Groups<ul> <li>https://www.meetup.com/topics/kubernetes/</li> </ul> </li> <li>Slack Channels: #kubernetes-users</li> <li>Mailing Lists<ul> <li>Users</li> <li>Developers</li> </ul> </li> <li>Special Interest Groups<ul> <li>Scheduling, authorization, networking, documentation, etc</li> <li>Existing SIGs</li> <li>New SIG Creation</li> </ul> </li> <li>Stack Overflow</li> <li>CNCF Events<ul> <li>Three of the major conferences it organizes are:<ul> <li>KubeCon + CloudNativeCon Europe</li> <li>KubeCon + CloudNativeCon North America</li> <li>KubeCon + CloudNativeCon China.</li> </ul> </li> </ul> </li> </ul> <p>Next Course: - Kubernetes Fundamentals - Kubernetes Administrator - Certified Kubernetes Adminsitrator Exam - Certified Kubernetes Application Developer Program</p>"},{"location":"networking/arp.html","title":"Address Resolution Protocol (ARP)","text":"<p>https://www.youtube.com/watch?v=NpiORFxyM4c</p> <ul> <li>ARP is a protocol for mapping an IP address to a physical MAC address on a local area network.</li> <li>Program used by one device to find another device's MAC address based on that device's IP</li> <li>Device's maintain ARP Cache tables mapping IP to MAC<ul> <li><code>arp -a</code> lists table</li> </ul> </li> </ul> <p>How does ARP work?</p> <ul> <li><code>Client</code> (<code>192.168.1.10</code>) wants to communicate with <code>Server</code> (<code>192.168.1.50</code>)</li> <li><code>Client</code> knows <code>Server</code> has IP of <code>192.168.1.50</code> and is local.<ol> <li><code>Client</code> broadcasts packet to all IPs:<ul> <li>\"Are you <code>192.168.1.50</code>? Please send MAC\"<ul> <li>IP Source: <code>192.168.1.10</code></li> <li>MAC Source: <code>oe:cd:ef:12:34:56</code></li> <li>IP Dest: <code>192.168.1.50</code></li> <li>MAC Dest: <code>ff:ff:ff:ff:ff:ff</code> (broadcast)</li> </ul> </li> <li>For each device that 'hears' broadcast: if not <code>192.168.1.50</code> silently ignore packet</li> </ul> </li> <li><code>Server</code> 'hears' packet - sends Unicast (1-to-1 communication) to <code>Client</code><ul> <li>IP Source: <code>192.168.1.50</code></li> <li>MAC Source: <code>fa:ed:db:91:11:19</code></li> <li>IP Dest: <code>192.168.1.10</code></li> <li>Mac Dest: <code>oe:cd:ef:12:34:56</code> (unicast)</li> </ul> </li> <li><code>Client</code> confirms by send <code>Server</code> a request<ul> <li>IP Source: <code>192.168.1.10</code></li> <li>MAC Source: <code>oe:cd:ef:12:34:56</code></li> <li>IP Dest: <code>192.168.1.50</code></li> <li>MAC Source: <code>fa:ed:db:91:11:19</code> (unicast)</li> <li><code>Client</code> updates ARP Cache table for future reference</li> </ul> </li> </ol> </li> </ul>"},{"location":"networking/arp.html#arp-summary","title":"ARP Summary","text":"<ol> <li>Layer 2 protocol (aruably as Layer 2.5 as it exists between layers)<ul> <li>Uses Layer 3 IP address to find Layer 2 MAC address</li> </ul> </li> <li>Operates on LAN (same broadcast domain)<ul> <li>Relies on broadcasting</li> </ul> </li> <li>Uses/Updates ARP Table</li> </ol>"},{"location":"networking/osi.html","title":"OSI Model","text":"<p>https://www.youtube.com/watch?v=nFnLPGk8WjA</p>"},{"location":"networking/osi.html#layers","title":"Layers","text":"Layer Name Mnemonic Mnemonic Mnemonic 7 Application All All Away 6 Presentation People People Pizza 5 Session Seem Should Sausage 4 Transport To Try Throw 3 Network Need New Not 2 Data Link Domino Dr. Do 1 Physical Pizza Pepper Please"},{"location":"networking/osi.html#physical-path","title":"Physical Path","text":"<ol> <li>Sending device starts with Application (Layer 7)</li> <li>Data moves down Layers from 7 =&gt; 1</li> <li>Data moves along Network medium</li> <li>Data moves up Layers from 1 =&gt; 7 to receiving device</li> </ol>"},{"location":"networking/osi.html#logical-path","title":"Logical Path","text":"Layer Sender Receiver Application Generates Data Receives Data Presentation Encrpyts/Compresses Decrypts/Decompresses Session Transport Chops into Segments Puts segments together Network Makes Packets Opens Packets Data Link Makes Frames Opens Frames Physical"},{"location":"networking/osi.html#layer-notes","title":"Layer Notes","text":""},{"location":"networking/osi.html#application-layer-7","title":"Application (Layer 7)","text":"<ul> <li>non-technical<ul> <li>About user's application<ul> <li>Chrome/Firefox/Outlook/etc</li> </ul> </li> </ul> </li> <li>technically<ul> <li>refers to application protocols<ul> <li>HTTP, SMTP, POP3, IMAP4, etc</li> <li>facilitate communications between application and operating system</li> </ul> </li> </ul> </li> <li>Application data generated here</li> </ul>"},{"location":"networking/osi.html#presentation-layer-6","title":"Presentation (Layer 6)","text":"<ul> <li>Provides variety of coding/conversion functions on application data</li> <li>Ensures information sent from app layer of client is understood by app layer of server</li> <li>trys to translate app data into certain format that every system can understand</li> </ul>"},{"location":"networking/osi.html#session-layer-5","title":"Session (Layer 5)","text":"<ul> <li>Establish, manage, terminate connectiosn between sender and receiver</li> </ul>"},{"location":"networking/osi.html#transport-layer-4","title":"Transport (Layer 4)","text":"<ul> <li>Accepts data from Session</li> <li>Chops data into smaller segments</li> <li>Adds Header information<ul> <li>Destination Port Number</li> <li>Source Port Number</li> <li>Sequence Number<ul> <li>used by receiver to put segments back in order</li> </ul> </li> </ul> </li> <li>Main Protocols:<ul> <li>TCP (dominant protocol)</li> <li>UDP</li> </ul> </li> </ul>"},{"location":"networking/osi.html#network-layer-3","title":"Network (Layer 3)","text":"<ul> <li>Primary Protocol: IP</li> <li>Takes segments and adds actual header information<ul> <li>Senders IP address</li> <li>Receivers IP address</li> <li>Packets are created</li> </ul> </li> <li>All about IP address and routing</li> </ul>"},{"location":"networking/osi.html#data-link-layer-2","title":"Data Link (Layer 2)","text":"<ul> <li>More Header information added<ul> <li>Adds Frame Header<ul> <li>Source MAC Address</li> <li>Desination MAC Address</li> </ul> </li> <li>Adds Trailing FCS</li> </ul> </li> <li>Exists @ NIC</li> </ul>"},{"location":"networking/osi.html#physical-layer-1","title":"Physical (Layer 1)","text":"<ul> <li>Accepts Frames from Data Link layers</li> <li>Generates Bits<ul> <li>Bits made of electrical pulses or light<ul> <li>depends on medium (copper vs fiber etc)</li> </ul> </li> </ul> </li> </ul>"},{"location":"networking/subnetting.html","title":"Subnetting","text":""},{"location":"networking/subnetting.html#ipv4-classes","title":"IPv4 Classes","text":"<ul> <li>Notes on https://www.youtube.com/watch?v=vcArZIAmnYQ&amp;list=PLSNNzog5eydt_plAtt3k_LYuIXrAS4aDZ</li> </ul> Class First Octet decimal (range) First Octet binary (range) IP Range Subnet Mask Hosts per Network ID # of Networks Class A 0-127 0XXXXXXX 0.0.0.0 - 127.255.255.255 255.0.0.0 2<sup>24</sup>-2 2<sup>7</sup> Class B 128-191 10XXXXXX 128.0.0.0 - 191.255.255.255 255.255.0.0 2<sup>16</sup>-2 2<sup>14</sup> Class C 192-223 110XXXXX 192.0.0.0 - 223.255.255.255 255.255.255.0 2<sup>8<sup>-2 2<sup>21</sup> Class D (Multicast) 224-239 1110XXXX 224.0.0.0 - 239.255.255.255 Class E (Experimental) 240-255 1111XXXX 240.0.0.0 - 255.255.255.255 h = 2<sup>x</sup>-2 n = 2<sup>y</sup> <ul> <li>h = 2<sup>x</sup>-2 ; <code>x</code> is the number of 0's (in binary) in the subnet mask</li> <li>n = 2<sup>y</sup> ; <code>y</code> is the number of 1's (in binary) in the subnet mask - only including unfixed values.<ul> <li>The fixed values in the First Octet (in binary) are not counted towards <code>y</code></li> </ul> </li> </ul>"},{"location":"networking/subnetting.html#subnet-masks","title":"Subnet Masks","text":"<p>https://www.youtube.com/watch?v=yLeuGOOrUvo&amp;list=PLSNNzog5eydt_plAtt3k_LYuIXrAS4aDZ&amp;index=4</p> <ul> <li>Why do we need them?<ul> <li>Indicates which devices are local vs remote.</li> </ul> </li> <li>How?<ul> <li>Compare Device IPs (in binary) where Subnet Mask (in binary) == <code>1</code></li> <li>Subnet Mask indicates which binary values from each device's IP should be used to decide if devices are local/remote.</li> </ul> </li> </ul>"},{"location":"networking/subnetting.html#example","title":"Example","text":"<ul> <li>Device <code>A</code> Subnet Mask: <code>255.255.255.0</code></li> <li>Device <code>A</code> IP Address: <code>10.1.151.2</code></li> <li>Device <code>B</code> IP Address: <code>10.1.151.3</code></li> <li>Device <code>C</code> IP Address: <code>64.227.160.23</code></li> </ul> <p>Convert Subnet Masks and IPs into Binary</p> Label 1<sup>st</sup> Octet 2<sup>nd</sup> Octet 3<sup>rd</sup> Octet 4<sup>th</sup> Octet <code>A</code>'s Subnet Mask <code>11111111</code> <code>11111111</code> <code>11111111</code> <code>00000000</code> <code>A</code>'s IP Address: <code>00001010</code> <code>00000001</code> <code>10010111</code> <code>00000010</code> <code>B</code>'s IP Address: <code>00001010</code> <code>00000001</code> <code>10010111</code> <code>00000011</code> Compare <code>A</code> to <code>B</code> Matches Matches Matches N/A - Subnet Mask is <code>0</code> <code>C</code>'s IP Address: <code>01000000</code> <code>11100011</code> <code>10100000</code> <code>00010111</code> Compare <code>A</code> to <code>C</code> Doesn't Match Doesn't Match Doesn't Match <ul> <li>Device <code>A</code> and <code>B</code> are on same network.</li> <li>Device <code>A</code> and <code>C</code> are on different networks.</li> </ul>"},{"location":"networking/subnetting.html#remote-vs-local-protocol","title":"Remote vs Local Protocol","text":"<ul> <li>Device <code>A</code> wants to communicate with Device <code>B</code> (local)<ol> <li><code>A</code> uses ARP to ask for <code>B</code>'s MAC Address via <code>B</code>'s IP<ul> <li>ARP: https://www.youtube.com/watch?v=NpiORFxyM4c</li> </ul> </li> <li><code>B</code> replies with <code>B</code>'s MAC Address</li> <li><code>A</code> uses <code>B</code>'s MAC to make Frames and communicate with <code>B</code></li> <li>All communication between <code>A</code> &amp; <code>B</code> via Switch (layer 2 Device)</li> </ol> </li> <li> <p>Device <code>A</code> wants to communicate with Device <code>C</code> (remote network)</p> <ol> <li><code>A</code> uses ARP to ask for Default Gateway's MAC Address based on Default Gateway's IP address.</li> <li>Default Gateway replies to <code>A</code> with Default Gateway's MAC Address</li> <li><code>A</code> sends packets (for <code>C</code>) to Default Gateway's MAC Address, which delivers <code>A</code>'s packets to remote computer <code>C</code></li> </ol> </li> <li> <p>ARP used in both Remote and Local communications</p> </li> <li>IP Address used for remote communications</li> <li>MAC Address used for local communications</li> <li>Switch (layer 2 device) used for Local communications</li> <li>Default Gateway (layer 3 device) used for Remote communications</li> </ul>"},{"location":"networking/subnetting.html#subnet-shorthand","title":"Subnet Shorthand","text":"<p><code>Shorthand</code> is the count of <code>1</code>'s in the binary form of the subnet mask.</p> Shorthand Binary Decimal /8 11111111.00000000.00000000.00000000 255.0.0.0 /16 11111111.11111111.00000000.00000000 255.255.0.0 /5 11111000.00000000.00000000.00000000 248.0.0.0 /20 11111111.11111111.11110000.0000 255.255.240.0 /25 11111111.11111111.11111111.10000000 255.255.255.128"},{"location":"networking/subnetting.html#subnetting-table","title":"Subnetting Table","text":"Subnet 1 2 4 8 16 32 64 Host 256 128 64 32 16 8 4 Subnet Mask /24 /25 /26 /27 /28 /29 /30"},{"location":"networking/subnetting.html#example-problems","title":"Example Problems","text":""},{"location":"networking/subnetting.html#example-1","title":"Example 1","text":"<ul> <li>IP Address Given: 192.168.1.0</li> <li>Hosts Needed: 60</li> <li>Subnets Needed: 4</li> </ul> <pre><code>                      ___\nSUBS:            2 |   4 |   8 |  16 | 32 |  64 | 128 | 256\n192.168.1.X:   128 |  64 |  32 |  16 |  8 |   4 |   2 |   1\nHOST:          256 | 128 |  64 |  32 | 16 |   8 |   4 |   2\n                            ^^\nCLASS: C                                     {    HOST IPS   }\nDEFAULT SNM: /24     192.168.1 { .0    +1 =&gt; | .1   &lt;-&gt; .62  | &lt;= -1 .63  }\nCUSTOM SNM: /26                { .64   +1 =&gt; | .65  &lt;-&gt; .126 | &lt;= -1 .127 } BROAD\nHOSTS(#-2): 62             NET { .128  +1 =&gt; | .129 &lt;-&gt; .190 | &lt;= -1 .191 } CAST\nSUBNETS: 4                     { .192  +1 =&gt; | .192 &lt;-&gt; .254 | &lt;= -1 .255 }\n                               { .256\n                                  ^^^ Invalid\n</code></pre>"},{"location":"pandas/pandas.html","title":"Pandas Notes","text":""},{"location":"pandas/pandas.html#data-structures","title":"Data Structures","text":"<ul> <li>Indexes: Sequence of labels<ul> <li>Immutable (Like dictionary keys</li> <li>Homogenous in data type (Like NumPy array)</li> </ul> </li> <li>Series: 1D array with Index</li> <li>DataFrames: 2D array with Series as columns</li> </ul>"},{"location":"pandas/pandas.html#index","title":"Index","text":""},{"location":"pandas/pandas.html#index-examples","title":"Index Examples","text":"<pre><code>import pandas as pd\nprices = [10.70, 10.86, 10.74, 10.71, 10.79]\nshares = pd.Series(prices) \ndays = ['Mon', 'Tue', 'Wed', 'Thur', 'Fri']\npd.Series(prices, index=days)\nshares.index.name = 'weekday'\n# Indivdual elements in index are immutable\nshares.index[2] = 'Wednesday' #error\n# entire index can be re-built\nshares.index = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n</code></pre>"},{"location":"pandas/pandas.html#index-multiple-values","title":"Index Multiple Values","text":"<p>Indexes can be built with multiple values using tuples</p> <pre><code>df = df.set_index(['col1', 'col2'])\nprint(df.index.name)\n=&gt; None\nprint(df.index.names)\n=&gt; ['col1', 'col2']\n</code></pre>"},{"location":"pandas/pandas.html#dfunstacklevelcol1","title":"df.unstack(level='col1')","text":"<p><code>df.unstack</code> a multilevel index results in the same type of hierarchical columns from <code>df.pivot</code></p>"},{"location":"pandas/pandas.html#dfstacklevelcol1","title":"df.stack(level='col1')","text":"<p><code>df.stack</code> hierarchical columns to create multilevel index</p>"},{"location":"pandas/pandas.html#dfswaplevel","title":"df.swaplevel()","text":"<p>swaps inner/outter indexes in multilevel index</p>"},{"location":"pandas/pandas.html#dfsort_index","title":"df.sort_index()","text":""},{"location":"pandas/pandas.html#pdmelt","title":"pd.melt()","text":"<pre><code>pd.melt(df, id_vars=['colN'], value_vars=['colN'])\npd.melt(df, id_vars=['colN'], var_name='col1', value_name='col2')\n</code></pre>"},{"location":"pandas/pandas.html#index-sorting","title":"Index Sorting","text":"<pre><code>df = df.sort_index()\n</code></pre>"},{"location":"pandas/pandas.html#dfloc","title":"df.loc[]","text":"<pre><code>stocks.loc[('CSCO', '2016-10-04')] # returns all columns\nstocks.loc[('CSCO', '2016-10-04'), 'col1'] # returns col1\nstocks.loc['CSCO'] # returns rows within 'CSCO' index\nstocks.loc['CSCO':'MSFT'] # returns rows with index b/t\nstocks.loc[(['AAPL', 'MSFT'], '2016-10-05']), :]\nstocks.loc[(['AAPL', 'MSFT'], '2016-10-05'), 'Close']\nstocks.loc[('CSCO', ['2016-10-05', '2016-10-03']), :]\n</code></pre>"},{"location":"pandas/pandas.html#slicing-both-indexes","title":"Slicing (both indexes)","text":"<pre><code>stocks.loc[(slice(None), slice('2016-10-03','2016-10-04')), :]\n\n# Look up data for CA and TX in month 2: CA_TX_month2\nCA_TX_month2 = sales.loc[(['CA', 'TX'], 2), :]\n\n# Look up data for all states in month 2: all_month2\nall_month2 = sales.loc[(slice(None), 2), :]\n</code></pre> <p>TODO(Wes) - go back to lecture on this</p>"},{"location":"pandas/pandas.html#dfiloc","title":"df.iloc[]","text":"<p>TODO(Wes)</p>"},{"location":"pandas/pandas.html#list-comprehensions","title":"List Comprehensions","text":"<p>TODO(Wes)</p>"},{"location":"pandas/pandas.html#rotating-pivot-data","title":"Rotating / Pivot Data","text":""},{"location":"pandas/pandas.html#dfpivot","title":"df.pivot()","text":"<pre><code>df.pivot(   index='col1'\n            ,columns='col2'\n            ,values='col3'      \n)\n\n# all columns used as values\ndf.pivot(index='col1' ,columns='col2'\n)\n</code></pre>"},{"location":"python/10apps.html","title":"Learn Python by Building 10 Apps","text":""},{"location":"python/10apps.html#accept-user-input","title":"Accept user input","text":"<pre><code>user_input = input(\"Prompt: \")\n</code></pre>"},{"location":"python/10apps.html#if-else-statements","title":"if / else statements","text":"<pre><code>if condition and condition or condition:\n    do some things\nelif conidtion or condition:\n    do some things\nelse:\n    do some things\n</code></pre>"},{"location":"python/10apps.html#while-loops","title":"while loops","text":"<pre><code>while True:\n    do some things\n</code></pre>"},{"location":"python/10apps.html#string-formatting","title":"string formatting","text":"<pre><code>name = 'Wes'\nprint(\"Hello {}\".format(name))\nprint(f\"Hello {name}\")\nprint(f'Hello {name}')\n</code></pre>"},{"location":"python/10apps.html#functions","title":"functions","text":"<pre><code>def my_function():\n    do some things\n    return new_thing\n</code></pre>"},{"location":"python/10apps.html#app3-birthday","title":"App3 - birthday","text":""},{"location":"python/10apps.html#dates","title":"dates","text":"<pre><code>import datetime\ntoday = datetime.date.today()\n# date = datetime.date(year, month, day)\nMay_1_2018 = datetime.date(2018, 5, 1)\ndays_difference = today.day - May_1_2018.day\n</code></pre>"},{"location":"python/10apps.html#times","title":"times","text":""},{"location":"python/10apps.html#timespans","title":"timespans","text":""},{"location":"python/10apps.html#app4","title":"App4","text":""},{"location":"python/10apps.html#multiple-files-modules","title":"multiple files / modules","text":""},{"location":"python/10apps.html#file-io","title":"file i/o","text":"<pre><code>import os\nfilename = os.path.abspath(os.path.join('.', 'journals', name + '.jrl'))\nif os.path.exists(filename):\n    with open(filename) as fin:\n        for entry in fin.readlines():\n            do some things\n\nwith open(filename, 'w') as fout:\n    for entry in journal_data:\n        fout.write(entry + '\\n')\n</code></pre>"},{"location":"python/10apps.html#os-independent-path-management","title":"os independent path management","text":"<pre><code>filename = os.path.abspath(os.path.join('.', 'journals', name + '.jrl'))\n</code></pre>"},{"location":"python/10apps.html#for-in-loops","title":"for-in loops","text":"<pre><code>for n in item:\n    print(n)\n</code></pre>"},{"location":"python/10apps.html#iterators","title":"iterators","text":""},{"location":"python/10apps.html#_-_name_-_","title":"_ _name_ _","text":"<pre><code>if __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"python/10apps.html#doc-strings","title":"doc strings","text":"<pre><code>def load(name):\n    \"\"\"\n    This method creates and loads a new journal.\n\n    :param name: The base name of the journal to load.\n    :return: A new journal data structure populated with the file data.\n    \"\"\"\n</code></pre>"},{"location":"python/10apps.html#app5","title":"App5","text":""},{"location":"python/10apps.html#screen-scraping","title":"screen scraping","text":"<pre><code>import requests\nimport bs4\nurl = 'https://www.wunderground.com/weather-forecast/72202'\n\n# get page\nresponse = requests.get(url)\n\n# parse html (reponse.text) into DOM\nsoup = bs4.BeautifulSoup(response.text, 'html.parser')\n\n# get location, condition, temp, scale (F vs C)\nloc = soup.find(class_='region-content-header').find('h1').get_text()\ncondition = soup.find(class_='condition-icon').get_text()\ntemp = soup.find(class_='wu-unit-temperature').find(\n    class_='wu-value').get_text()\nscale = soup.find(class_='wu-unit-temperature').find(\n    class_='wu-label').get_text()\n</code></pre>"},{"location":"python/10apps.html#http-requests","title":"http requests","text":"<pre><code>import requests\nurl = 'https://www.wunderground.com/weather-forecast/72202'\nresponse = requests.get(url)\n</code></pre>"},{"location":"python/10apps.html#virtual-environments","title":"virtual environments","text":""},{"location":"python/10apps.html#tuples-and-named-tuples","title":"tuples and named tuples","text":"<pre><code>m = (22.5, 44.234, 19.02, 'strong')\n\ntemp = m[0]\nquality = m[3]\n\nm = 22.5, 44.234, 19.02, 'strong'\n\nprint(m)  # (22.5, 44.234, 19.02, 'strong') \n\nt, la, lo, q = m\n# t=22.5, la=44.234, lo=19.02, q='strong'\n</code></pre> <pre><code>import collections\n\nWeatherReport = collections.namedtuple(\n    'Measurement',\n    'temp, lat, long, quality')\n\nm = Measurement(22.5, 44.234, 19.02, 'strong')\n\ntemp = m[0]\ntemp = m.temp\nquality = m.quality\n\nprint(m)\n\n#  Measurement(temp=22.5, lat=44.234, long=19.02, quality='strong')\n</code></pre>"},{"location":"python/10apps.html#beautiful-soup-package","title":"beautiful soup package","text":"<pre><code>import bs4\n\nsoup = bs4.BeautifulSoup(reponse.text, 'html.parser')\n</code></pre>"},{"location":"python/10apps.html#slicing","title":"slicing","text":"<pre><code>nums = [2, 3, 5, 6, 11, 13, 17, 19, 23]\n\nfirst_prime = nums[0]  # 2\nlast_prime = nums[-1]  # 23\n\nlowest_four = nums[0:4]  # [2, 3, 5, 7]\nlowest_four = nums[:4]  # [2, 3, 5, 7]\n\nMiddle = nums[3:6]  # [7, 11, 13]\n\nlast_four = nums[5:9]  # [13, 17, 19, 23]\nlast_four = nums[5:]  # [13, 17, 19, 23]\n\nlast_four = nums[-4:]  # [13, 17, 19, 23]\n</code></pre>"},{"location":"python/10apps.html#app6","title":"App6","text":""},{"location":"python/10apps.html#http-clients-binary-data","title":"http clients (binary data)","text":"<pre><code>import os\nimport shutil\nimport requests\n\ndef get_cat(folder, name):\n    url = 'http://consuming-python-services-api.azurewebsites.net/cats/random'\n    data = get_data_from_url(url)\n    save_image(folder, name, data)\n\ndef get_data_from_url(url):\n    response = requests.get(url, stream=True)\n    return response.raw\n\ndef save_image(folder, name, data):\n    file_name = os.path.join(folder, name + '.jpg')\n    with open(file_name, 'wb') as fout:\n        shutil.copyfileobj(data, fout)\n</code></pre>"},{"location":"python/10apps.html#subprocesses-platform","title":"subprocesses / platform","text":"<pre><code>import platform\nif platform.system() == 'Darwin':\n    subprocess.call(['open', folder])\nelif platform.system() == 'Windows':\n    subprocess.call(['explorer', folder])\nelif platform.system() == 'Linux':\n    subprocess.call(['xdg-open', folder])\nelse:\n    print(\"We don't support your os: \" + platform.system())\n</code></pre>"},{"location":"python/10apps.html#app-7","title":"App 7","text":""},{"location":"python/10apps.html#classes","title":"classes","text":"<pre><code>class Creature:\n    # initializer\n    def __init__(self, name, level):\n        self.name = name\n        self.level = level\n\n    def __repr__(self):\n        return \"Creature {} of level {}\".format(\n            self.name, self.level\n        )\n\n    def walk(self):\n        print('{} walks around'.format(self.name))\n</code></pre>"},{"location":"python/10apps.html#inheritance","title":"inheritance","text":"<pre><code>class Dragon(Creature):\n\n    def __init__(self, name, level, scale_thickness):\n        super().__init__(name, level) # initializer for Creature\n        self.scale_thickness = scale_thickness\n\n    def breath_fire(): ...\n</code></pre>"},{"location":"python/10apps.html#duck-typing-and-polymorphism","title":"duck typing and polymorphism","text":"<pre><code># all types derive from Creature\ncreatures = [\n        SmallAnimal('Toad', 1),\n        Creature('Tiger', 12),\n        SmallAnimal('Bat', 3),\n        Dragon('Dragon', 50, 75),\n        Wizard('Evil Wizard', 1000)\n    ]\n\nwiard = Wizard('Gandolf', 22)\n\nfor c in creatures:\n    wizard.attack(c)\n# Wizard knows how to battle any type of Creature\n\n# Duck Typing\n# \"If it looks/acts like a Duck -- it's a duck\"\n# wizard.attack(c) in most languages would require 'c'\n# to have inherited from Creature, given that .attack()\n# takes a creature. Python's Duck Typing takes\n# 'things that look like creatures'\n</code></pre>"},{"location":"python/10apps.html#app8","title":"App8","text":""},{"location":"python/10apps.html#generator-methods","title":"generator methods","text":"<pre><code># yield makes fibonacci a generator method\ndef fibonacci(limit):\n    current = 0\n    next = 1\n\n    # after item is returned and processed,\n    # execution returns and resumes\n    while current &lt; limit:\n        current, next = next, next + current\n        yield current\n        # yield keyword returns one element of a sequence\n</code></pre>"},{"location":"python/10apps.html#yield-from","title":"yield from","text":"<pre><code>def search_folders(folder, text):\n    # for macOS if .DS_Store error\n    # glob.glob(os.path.join(folder, '*'))\n    items = os.listdir(folder)\n\n    for item in items:\n        full_item = os.path.join(folder, item)\n        if os.path.isdir(full_item):\n            yield from search_folders(full_item, text)\n        else:\n            yield from search_file(full_item, text)\n\ndef search_file(filename, search_text):\n    # matches = []\n    with open(filename, 'r', encoding='utf-8') as fin:\n\n        line_num = 0\n        for line in fin:\n            line_num += 1\n            if line.lower().find(search_text) &gt;= 0:\n                m = SearchResult(line=line_num, file=filename, text=line)\n                yield m\n</code></pre>"},{"location":"python/10apps.html#recursion","title":"recursion","text":"<pre><code>def factorial(n):\n    # base case - break out of loop\n    if n &lt;= 1:\n        return 1\n\n    return n * factorial(n - 1)\n</code></pre>"},{"location":"python/10apps.html#app9","title":"App9","text":""},{"location":"python/10apps.html#dictionaries","title":"dictionaries","text":"<pre><code>info = dict()\ninfo['age'] = 42\ninfo['loc'] = 'Italy'\n\ninfo = dict(age=42, loc='Italy')\ninfo = {'age': 42, 'loc': 'Italy'}\n\nlocation = info['loc']\n\nif 'age' in info:  # test for key\n    # use info['age']\n</code></pre>"},{"location":"python/10apps.html#lambda-methods","title":"lambda methods","text":"<pre><code>def find_sig_nums(nums, predicate):\n    for n in nums:\n        if predicate(n):\n            yield n\n\nnumber = [1, 1, 2, 3, 5, 8, 21, 34]\nsig = find_sig_nums(numbers, lambda x: x % 2 == 1)\n# sig -&gt; [1, 1, 3, 5, 13, 21]\n</code></pre>"},{"location":"python/10apps.html#csv-file-format-and-parsing","title":"csv file format and parsing","text":"<pre><code>class Purchase:\n    def __init__(self, street, city, zipcode, state, beds, baths, sq__ft,\n                 home_type, sale_date, price, latitude, longitude):\n        self.longitude = longitude\n        self.latitude = latitude\n        self.price = price\n        self.sale_date = sale_date\n        self.type = home_type\n        self.sq__ft = sq__ft\n        self.baths = baths\n        self.beds = beds\n        self.state = state\n        self.zip = zipcode\n        self.city = city\n        self.street = street\n\n    @staticmethod\n    def create_from_dict(lookup):\n        return Purchase(\n            lookup['street'],\n            lookup['city'],\n            lookup['zip'],\n            lookup['state'],\n            int(lookup['beds']),\n            int(lookup['baths']),\n            int(lookup['sq__ft']),\n            lookup['type'],\n            lookup['sale_date'],\n            float(lookup['price']),\n            float(lookup['latitude']),\n            float(lookup['longitude'])\n        )\n\n\ndef load_file(filename):\n    with open(filename, 'r', encoding='utf-8') as fin:\n        reader = csv.DictReader(fin)\n        purchases = []\n        for row in reader:\n            p = Purchase.create_from_dict(row)\n            purchases.append(p)\n\n        return purchases\n</code></pre>"},{"location":"python/10apps.html#coding-for-python-3-and-2","title":"coding for python 3 and 2","text":"<pre><code>try:\n    import statistics # only Python 3.4.3+\nexcept:\n    import statistics_2_stand_in as statistics\n\n\nnumbers = [1, 6, 99, ..., 5]\nthe_avg = statistics.mean(numbers)\n\n# statistics_2_stand_in.py\ndef mean(lst):\n    # your implementation of mean here...\n    return avg\n</code></pre>"},{"location":"python/10apps.html#list-comprehensions","title":"list comprehensions","text":"<pre><code>paying_usernames = [\n    u.name                          # projection\n    for u in get_active_customers() # source\n    if u.last_purchase == today     # filter\n]\n</code></pre>"},{"location":"python/10apps.html#generator-expressions","title":"generator expressions","text":"<pre><code># works like generator methods / yield\npaying_usernames = (\n    u.name\n    for u in get_active_customers()\n    if u.last_purchase == today\n)\n\n# You can not index into generators\n</code></pre>"},{"location":"python/10apps.html#data-pipelines","title":"data pipelines","text":"<pre><code>all_transactions = get_tx_stream()\n\ninteresting_tx = (\n    tx\n    for tx in all_transactions  # calls transaction stream\n    if is_interesting(tx)\n)\n\npotentially_sellable_tx = (\n    tx\n    for tx in interesting_tx  # calls above\n    if is_sellable(tx)\n)\n\nnearby_sellable_interesting_tx = (\n    tx\n    for tx in potentially_sellable_tx  # calls above\n    if is_nearby(tx)\n)\n</code></pre>"},{"location":"python/10apps.html#app10","title":"App10","text":""},{"location":"python/10apps.html#error-and-exception-handling","title":"error and exception handling","text":"<pre><code>if not search_text or not search_text.strip():\n    raise ValueError(\"Search text is required.\")\n</code></pre>"},{"location":"python/10apps.html#try-except","title":"try / except","text":"<pre><code>try:\n    method1()\n    method2()\n    method3()\nexcept ConnectionError as ce:\n    # handle network error\nexcept Exception as x:\n    # handle general error\n</code></pre>"},{"location":"python/10apps.html#handling-errors-by-type","title":"handling errors by type","text":"<pre><code>try:\n    search = input(\"Movie search text (x to exit): \")\n    if search != 'x':\n        results = movie_svc.find_movies(search)\n        print(\"Found {} results.\".format(len(results)))\n        for r in results:\n            print(\"{} -- {}\".format(\n                r.year, r.title\n            ))\n        print()\n# Order from more specfic to more general\nexcept ValueError:\n    print(\"Error: Search text is required.\")\nexcept requests.exceptions.ConnectionError:\n    print(\"Error: Your network is down.\")\nexcept Exception as x:\n    print(\"Unexpected error. Details: {}\".format(x))\n</code></pre>"},{"location":"python/10apps.html#raising-errors","title":"raising errors","text":"<pre><code>def find_movies(search_text):\n    if not search_text or not search_text.strip():\n        raise ValueError(\"Search text is required.\")\n        # raise will immediately return from function with error\n</code></pre>"},{"location":"sas/sas.html","title":"SAS","text":""},{"location":"sas/sas.html#style","title":"Style","text":""},{"location":"sas/sas.html#determine-runtime-environment","title":"Determine Runtime Environment","text":"<pre><code>%macro check;\n\n  %if %symexist(_clientapp) %then %do;\n   %if &amp;_clientapp = SAS Studio %then %do;\n    %put Running SAS Studio;\n   %end;\n   %else %if &amp;_clientapp= 'SAS Enterprise Guide' %then %do;\n    %put Running SAS Enterprise Guide; \n   %end;\n  %end;\n\n  %else %if %index(&amp;sysprocessname,DMS) %then %do;\n    %put Running in Display Manager;\n  %end;\n  %else %if %index(&amp;sysprocessname,Program) %then %do;\n     %let prog=%qscan(%superq(sysprocessname),2,%str( ));\n     %put Running in batch and the program running is &amp;prog;\n  %end;\n\n  %mend check;\n %check\n</code></pre>"}]}